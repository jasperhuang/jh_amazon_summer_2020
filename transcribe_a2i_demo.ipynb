{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Amazon Transcribe transcriptions using Custom Vocabularies and Amazon Augmented AI (A2I)\n",
    "\n",
    "\n",
    "\n",
    "This notebook accompanies the blog \"Improving Amazon Transcribe transcriptions using Custom Vocabularies and Amazon Augmented AI (A2I)\" (TODO: add link)\n",
    "\n",
    "## Introduction\n",
    "When transcribing speech containing domain-specific terminologies in fields such as legal, financial, construction, higher education, or engineering, Amazon Transcribe’s [custom vocabularies](https://docs.aws.amazon.com/transcribe/latest/dg/how-vocabulary.html) feature can improve transcription quality. \n",
    "\n",
    "To use custom vocabularies with Amazon Transcribe, you need a list of domain-specific terms. If you have a collection of videos or audio files (dataset) that you want transcribed with high accuracy, you can use a portion of your dataset to Amazon Transcribe to assess which terms it has difficulty with (low confidence predictions). You can use Amazon A2I to send these low-confidence predictions directly to a human to review and manually transcribe the terms. This walkthrough will demonstrate how you can process the results obtained from Amazon A2I to quickly to build a custom vocabulary.\n",
    "\n",
    "In summary, in this walkthrough you will:\n",
    "* Send a subset of videos to Amazon Transcribe to find terms that are difficult to transcribe.\n",
    "* Set up a human review workflow using Amazon A2I to send low-confidence predictions to humans for manual review and transcription.\n",
    "* Create a custom vocabulary using the results obtained from human workers.\n",
    "* Test Amazon Transcribe on another subset of videos to asses the improvement in transcription quality. \n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook, you can simply execute each cell in order. To understand what's happening, you'll need:\n",
    "\n",
    "* An S3 bucket you can write to -- please provide its name in BUCKET. The bucket must be in the same region as this SageMaker Notebook instance. You can also change the EXP_NAME to any valid S3 prefix. All the files related to this experiment will be stored in that prefix of your bucket.\n",
    "* Familiarity with the Amazon A2I.\n",
    "* Familiarity with Python and numpy.\n",
    "* Basic familiarity with AWS S3.\n",
    "* Basic understanding of Amazon Transcribe and custom vocabularies. \n",
    "* Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "\n",
    "This notebook has only been tested on a SageMaker notebook instance. The runtimes given are approximate. We used an ml.t2.medium instance in our tests. However, you can likely run it on a local instance by first executing the cell below on SageMaker and then copying the role string to your local copy of the notebook.\n",
    "\n",
    "For more sample notebooks using A2I, visit this [Github repository](https://github.com/aws-samples/amazon-a2i-sample-jupyter-notebooks).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Latest SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 14.2MB/s ta 0:00:01  4% |█▌                              | 71kB 3.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-20.1.1\n",
      "\u001b[33mYou are using pip version 20.1.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.2-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.3.3)\n",
      "Collecting botocore<1.18.0,>=1.17.2\n",
      "  Downloading botocore-1.17.2-py2.py3-none-any.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.2->boto3) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.2->boto3) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.2->boto3) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.2->boto3) (1.11.0)\n",
      "\u001b[31mERROR: awscli 1.18.39 has requirement botocore==1.15.39, but you'll have botocore 1.17.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.15.39\n",
      "    Uninstalling botocore-1.15.39:\n",
      "      Successfully uninstalled botocore-1.15.39\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.12.39\n",
      "    Uninstalling boto3-1.12.39:\n",
      "      Successfully uninstalled boto3-1.12.39\n",
      "Successfully installed boto3-1.14.2 botocore-1.17.2\n",
      "Requirement already up-to-date: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import uuid\n",
    "import botocore\n",
    "import boto3\n",
    "import time\n",
    "import pprint\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon S3 (S3) client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "#Transcribe Client\n",
    "transcribe = boto3.client(\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region, Bucket, and Paths\n",
    "Make sure all your resources are stored in the same region. You'll be using the same bucket for this entire walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"chopt-a2i-test-sagemaker\"\n",
    "EXP_NAME = 'videos' # Any valid S3 prefix.\n",
    "OUTPUT_PATH = f's3://{BUCKET}/a2i-results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "s3 = boto3.client('s3')\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "assert bucket_region == region, \"Your S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following policies to this role in IAM:\n",
    "* AmazonAugmentedAIFullAccess\n",
    "* AmazonTranscribeFullAccess\n",
    "\n",
    "Or you can add a single policy, which will grant permissions to Amazon A2I and all integrated services (Amazon Rekognition and Amazon Transcribe)\n",
    "* AmazonAugmentedAIIntegratedAPIAccess\n",
    "\n",
    "Your execution role has the AmazonSageMakerFullAccess policy attached. This gives Amazon SageMaker permission to access your resources in S3 if the bucket or objects have the word `sagemaker` in the name. If your S3 bucket listed in `BUCKET` does not have sagemaker in the name, you will need to add an S3 policy to your execution role to give your role permissions to access your data objects in S3. The following is an example of an S3 policy:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::my_input_bucket/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::my_output_bucket/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = role.split('/')[-1]\n",
    "print(f'Your execution role name: {role_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Sample Video to S3\n",
    "For this demo, we'll be analyzing videos on getting started with Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./videos\n",
    "!aws s3 sync s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/ ./videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$BUCKET\"\n",
    "aws s3 cp ./videos/ s3://$1/a2i_transcribe_demo/videos --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Basic Transcription Job\n",
    "Our first step is to look at the performance of Amazon Transcribe using default parameters and establish a baseline for comparison. Once you have the SageMaker video mp4 file uploaded to an S3 bucket, you can use the transcribe function to start a transcription job. Note that the `vocab_name` parameter will be used later to specify custom vocabularies, and it’s currently defaulted to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS-sage-vid-0-16.52.02', 'AWS-sage-vid-1-16.52.02']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can give the transcription job any name.\n",
    "# job_name_1 = \"AWS-sage-1\"\n",
    "\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%H.%M.%S\")\n",
    "\n",
    "job_names = []\n",
    "for i in range(2):\n",
    "    job_names.append(\"AWS-sage-vid-\" + str(i) + \"-\" + str(time_now))\n",
    "\n",
    "# Path to folder\n",
    "folder_path = f\"s3://{BUCKET}/a2i_transcribe_demo/videos/\"\n",
    "\n",
    "all_videos = [\n",
    "             'Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4',\n",
    "             'Built-in Machine Learning Algorithms with Amazon SageMaker - a Deep Dive.mp4',\n",
    "             'Bring Your Own Custom ML Models with Amazon SageMaker.mp4',\n",
    "             'Train Your ML Models Accurately with Amazon SageMaker.mp4',\n",
    "             'Deploy Your ML Models to Production at Scale with Amazon SageMaker.mp4',\n",
    "             'Tune Your ML Models to the Highest Accuracy with Amazon SageMaker Automatic Model Tuning.mp4',\n",
    "             'Scale up Training of Your ML Models with Distributed Training on Amazon SageMaker.mp4',\n",
    "             'Use the Deep Learning Framework of Your Choice with Amazon SageMaker.mp4',\n",
    "             'Learn to Analyze the Co-Relation in Your Datasets Using Feature Engineering with Amazon SageMake.mp4',\n",
    "             'Get Scheduled Predictions on Your ML Models with Amazon SageMaker Batch Transform.mp4'\n",
    "]\n",
    "job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a transcribe function\n",
    "def transcribe(job_name, job_uri, out_bucket, format=\"mp4\", vocab_name=None):\n",
    "    \"\"\"Transcribe a .wav or .mp4 file to text.\n",
    "    Args:\n",
    "        job_name (str): the name of the job that you specify;\n",
    "                        the output json will be job_name.json\n",
    "        job_uri (str): input path (in s3) to the file being transcribed\n",
    "        out_bucket (str): s3 bucket name that you want the output json\n",
    "                          to be placed in\n",
    "        format (str): mp4 or wav for input file format;\n",
    "                      defaults to mp4\n",
    "        vocab_name (str): name of custom vocabulary used;\n",
    "                          optional, defaults to None\n",
    "    \"\"\"\n",
    "    \n",
    "    if format not in ['mp3','mp4','wav','flac']:\n",
    "        print(\"Invalid format\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(\"------\" + format)\n",
    "        if vocab_name is None:\n",
    "            transcribe.start_transcription_job(\n",
    "                TranscriptionJobName=job_name,\n",
    "                Media={\"MediaFileUri\": job_uri},\n",
    "                MediaFormat=format,\n",
    "                LanguageCode=\"en-US\",\n",
    "                OutputBucketName=out_bucket,\n",
    "            )\n",
    "        else:\n",
    "            transcribe.start_transcription_job(\n",
    "                TranscriptionJobName=job_name,\n",
    "                Media={\"MediaFileUri\": job_uri},\n",
    "                MediaFormat=format,\n",
    "                LanguageCode=\"en-US\",\n",
    "                OutputBucketName=out_bucket,\n",
    "                Settings={'VocabularyName': vocab_name}\n",
    "            )\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(transcribe.get_transcription_job(TranscriptionJobName=job_name))\n",
    "        \n",
    "#         while True:\n",
    "#             status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "#             if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "#                 break\n",
    "#             print(\"Not ready yet...\")\n",
    "#             time.sleep(5)\n",
    "#         print(status)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------mp4\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'AWS-sage-vid-0-16.52.02', 'TranscriptionJobStatus': 'IN_PROGRESS', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp4', 'Media': {'MediaFileUri': 's3://chopt-a2i-test-sagemaker/a2i_transcribe_demo/videos/Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4'}, 'Transcript': {}, 'StartTime': datetime.datetime(2020, 6, 15, 16, 52, 6, 844000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 6, 15, 16, 52, 6, 789000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '5a646189-5abc-4b05-8303-ba387641644c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Mon, 15 Jun 2020 16:52:08 GMT', 'x-amzn-requestid': '5a646189-5abc-4b05-8303-ba387641644c', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '484', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "------mp4\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'AWS-sage-vid-1-16.52.02', 'TranscriptionJobStatus': 'IN_PROGRESS', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp4', 'Media': {'MediaFileUri': 's3://chopt-a2i-test-sagemaker/a2i_transcribe_demo/videos/Built-in Machine Learning Algorithms with Amazon SageMaker - a Deep Dive.mp4'}, 'Transcript': {}, 'StartTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 239000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 214000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '69aaca79-983c-4575-9b5b-00f02effd6a6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Mon, 15 Jun 2020 16:52:11 GMT', 'x-amzn-requestid': '69aaca79-983c-4575-9b5b-00f02effd6a6', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '488', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    transcribe(job_names[i], folder_path+all_videos[i], BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NextToken': '3/Q22yZ4n/FldYqPp93ifuqNwQiBFLLG4HogrGDUAw+BR0LPkrXhXC5f+d4frPYCT5LCa+7bI0aMY9vrFMba9/2ruw/cEp5GaY5dATZ9K9bz5LFw9YKqH9mLILwskgN+Uqwtwx+oTpFWcqVuNNLyNqVReMPodrIAZ2XfX418THYDHrZ9bHewFxTAgUozladyi79AsI9TIyhXBzmKia1hx33l1cssw1WeDb/fo3VcngyXuLV3hQyzf3cmjoiGz9lFK4WZjOxwLKvpEsOwlo6MyLLYhJ7ZxlVmFLmKxswip8xSa+2TYPAtq/uHWB77am4v0dQ+twTC6eZYvGEIdIzMqrmSJrLcGEtV3jLRs6W90u+LuW7PLcauN2rsiQDdecHXKVdlqCpw5tgvrIFZ83ozm3W0OkGkvmcsEwQtlCGPpd9N7b5IUwoscQkUMOVTbHffbyojE0JViaKd5khoZYUuzKVc2LP871FAXSBjOnLIiNSw/Qhb95jVNjmYLt4EW6rHaU07tD3VYW8YJMliMJGW+WLTm/o4bIz1Z9XrD49XYPrOpBmUpVARfI8B++B/HG+PdcTYexScT+NyGlQPofdBI3aHePSbNkDv++3dSnyT+NTYvnvnS/DCZoakRZm9KHuFGzjFKGgwqlxWtSIZ7ZYfoBzxMV6mN/igQevQ0gwhTubRv84xs3n/2eCSCPdRPICgwlgH3E8kLnkBhje2rxsChTE8HGi0RL2QeN/T/txS95RxrRKpyzKA6TTZszcJf0tv4EqB/u8JNgO2Y21sKxOi6e4Aquyyif4KS8e0zyE8McGUp6ZllYxoz7VashsJBQodczKRj8LwMj41y1/cRnKFry0NkjEZW/l2j9IUsgshzU0fsGT34NMbLW51FrFy3Y8ZmXa8KqbN9g6fVN9zWJF6EX0xe+2PiTLTvE7aCQ',\n",
       " 'TranscriptionJobSummaries': [{'TranscriptionJobName': 'AWS-sage-vid-1-16.52.02',\n",
       "   'CreationTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 214000, tzinfo=tzlocal()),\n",
       "   'StartTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 239000, tzinfo=tzlocal()),\n",
       "   'CompletionTime': datetime.datetime(2020, 6, 15, 16, 55, 2, 788000, tzinfo=tzlocal()),\n",
       "   'LanguageCode': 'en-US',\n",
       "   'TranscriptionJobStatus': 'COMPLETED',\n",
       "   'OutputLocationType': 'CUSTOMER_BUCKET'}],\n",
       " 'ResponseMetadata': {'RequestId': '5892e7f4-1d3e-4946-9b81-35e161fa26d9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 15 Jun 2020 16:57:01 GMT',\n",
       "   'x-amzn-requestid': '5892e7f4-1d3e-4946-9b81-35e161fa26d9',\n",
       "   'content-length': '1225',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe.list_transcription_jobs(JobNameContains=job_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NextToken': '3/Q22yZ4n/FldYqPp93ifuqNwQiBFLLG4HogrGDUAw+BR0LPkrXhXC5f+d4frPYCT5LCa+7bI0aMY9vrFMba9/2ruw/cEp5GaY5dATZ9K9bz5LFw9YKqH9mLILwskgN+Uqwtwx+oTpFWcqVuNNLyNqVReMPodrIAZ2XfX418THYDHrZ9bHewFxTAgUozladyi79AsI9TIyhXBzmKia1hx33l1cssw1WeDb/fo3VcngyXuLV3hQyzf3cmjoiGz9lFK4WZjOxwLKvpEsOwlo6MyLLYhJ7ZxlVmFLmKxswip8xSa+2TYPAtq/uHWB77am4v0dQ+fNVWRelfUmKDA3ZO9l4OG4cgfm2a5EGBvScE9/EOenwNQGfqq0g8/IezLbOsC4a5RB5QLLfeKEac8ADieVxNXo07oca2g3cNk4c2maYTTKVZ5UyKTfyCn+kvcREBkBpDoOIhu0jFfQxVJEqtCvIBqmSxJ+qi24bteDIx+V81u2A4mCMjHPnoZ0MCg6VOrfVurDCQ+vzPslR2pGsj2KmT82z9X6KSqJNEzcOr9iw8/MRMSUhfVzUxfjHJR58h7Rj6CxHJ2WKku5w/l7h7eb42q+IdurC/kCtkqOv8Pt4xvYPgTYYFQGfRfeeOGcoh3tPlzAN3cw9PoW1fmP7CpOLIqxYlzTzixXDMbJnkLsT4Le7XDLT/1NZWiKaRiI0xow70vivOPCDSmiIWiJpF6dC9rYcfc1E1wXKd/CBVSnsAzdZcaqIbl91qgDobSG7zmqfS3pPjcss7onfx+iTdF+LcD1yp3EJX3RUZ8IAhBL8lfs3muRBiZm7DEB3LRUl1/tnVSG38MGLQJvemyqYLL4BC4X15nIWT1TlCAP5cS9YSKHAKZM8ltEvaEuo9nrufIrot9vzkD6kf0rlNAPp4iBdE+TwX9VOuMkfU3Q',\n",
       " 'TranscriptionJobSummaries': [{'TranscriptionJobName': 'AWS-sage-vid-1-16.52.02',\n",
       "   'CreationTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 214000, tzinfo=tzlocal()),\n",
       "   'StartTime': datetime.datetime(2020, 6, 15, 16, 52, 9, 239000, tzinfo=tzlocal()),\n",
       "   'CompletionTime': datetime.datetime(2020, 6, 15, 16, 55, 2, 788000, tzinfo=tzlocal()),\n",
       "   'LanguageCode': 'en-US',\n",
       "   'TranscriptionJobStatus': 'COMPLETED',\n",
       "   'OutputLocationType': 'CUSTOMER_BUCKET'}],\n",
       " 'ResponseMetadata': {'RequestId': 'a486d3be-b0e8-418f-bdd7-73970af3253f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 15 Jun 2020 16:57:17 GMT',\n",
       "   'x-amzn-requestid': 'a486d3be-b0e8-418f-bdd7-73970af3253f',\n",
       "   'content-length': '1225',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe.list_transcription_jobs(JobNameContains=job_names[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Parse Transcription Results\n",
    "\n",
    "When the transcription job finishes, the results will be stored in your specified S3 bucket as an output JSON file called “YOUR_JOB_NAME.json.” You can use the following function to retrieve your results, and parse them into sentences with time stamps, confidence scores, and other useful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_text_and_timestamps(bucket_name, file_name):\n",
    "    \"\"\"take json file from S3 bucket and returns a tuple of:\n",
    "       entire transcript, list object of tuples of timestamp and individual sentences\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): name of s3 bucket\n",
    "        file_name (str): name of file\n",
    "    Returns:\n",
    "        (\n",
    "        entire_transcript: str,\n",
    "        sentences_and_times: [ {start_time (sec) : float,\n",
    "                                end_time (sec)   : float,\n",
    "                                sentence         : str,\n",
    "                                min_confidence   : float (minimum confidence score of that sentence)\n",
    "                                } ],\n",
    "        confidences:  [ {start_time (sec) : float,\n",
    "                         end_time (sec)   : float,\n",
    "                         content          : str, (single word/phrase)\n",
    "                         confidence       : float (confidence score of the word/phrase)\n",
    "                         } ],\n",
    "        scores: list of confidence scores\n",
    "        )\n",
    "    \"\"\"\n",
    "    s3_clientobj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    original = json.loads(s3_clientdata)\n",
    "    items = original[\"results\"][\"items\"]\n",
    "    entire_transcript = original[\"results\"][\"transcripts\"]\n",
    "\n",
    "    sentences_and_times = []\n",
    "    temp_sentence = \"\"\n",
    "    temp_start_time = 0\n",
    "    temp_min_confidence = 1.0\n",
    "    newSentence = True\n",
    "    \n",
    "    confidences = []\n",
    "    scores = []\n",
    "\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        # always add the word\n",
    "        if item[\"type\"] == \"punctuation\":\n",
    "            temp_sentence = (\n",
    "                temp_sentence.strip() + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            )\n",
    "        else:\n",
    "            temp_sentence = temp_sentence + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            temp_min_confidence = min(temp_min_confidence,\n",
    "                                      float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "            confidences.append({\"start_time\": float(item[\"start_time\"]),\n",
    "                                \"end_time\": float(item[\"end_time\"]),\n",
    "                                \"content\": item[\"alternatives\"][0][\"content\"],\n",
    "                                \"confidence\": float(item[\"alternatives\"][0][\"confidence\"])\n",
    "                               })\n",
    "            scores.append(float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "\n",
    "        # if this is a new sentence, and it starts with a word, save the time\n",
    "        if newSentence == True:\n",
    "            if item[\"type\"] == \"pronunciation\":\n",
    "                temp_start_time = float(item[\"start_time\"])\n",
    "            newSentence = False\n",
    "        # else, keep going until you hit a punctuation\n",
    "        else:\n",
    "            if (\n",
    "                item[\"type\"] == \"punctuation\"\n",
    "                and item[\"alternatives\"][0][\"content\"] != \",\"\n",
    "            ):\n",
    "                # end time of sentence is end_time of previous word\n",
    "                end_time = items[i-1][\"end_time\"] if i-1 >= 0 else items[0][\"end_time\"]\n",
    "                sentences_and_times.append(\n",
    "                    {\"start_time\": temp_start_time,\n",
    "                     \"end_time\": end_time,\n",
    "                     \"sentence\": temp_sentence.strip(),\n",
    "                     \"min_confidence\": temp_min_confidence\n",
    "                    }\n",
    "                )\n",
    "                # reset the temp sentence and relevant variables\n",
    "                newSentence = True\n",
    "                temp_sentence = \"\"\n",
    "                temp_min_confidence = 1.0\n",
    "                \n",
    "        i = i + 1\n",
    "\n",
    "    return entire_transcript, sentences_and_times, confidences, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AWS-sage-vid-0-16.52.02.json'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_names[0]+'.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_transcript_1, sentences_and_times_1, confidences_1, scores_1 = get_transcript_text_and_timestamps(BUCKET,job_names[0]+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entire_transcript = []\n",
    "all_sentences_and_times = []\n",
    "all_confidences = []\n",
    "all_scores = []\n",
    "for i in range(len(job_names)):\n",
    "    entire_transcript_1, sentences_and_times_1, confidences_1, scores_1 = get_transcript_text_and_timestamps(BUCKET,job_names[i]+\".json\")\n",
    "    all_entire_transcript.append(entire_transcript_1)\n",
    "    all_sentences_and_times.append(sentences_and_times_1)\n",
    "    all_confidences.append(confidences_1)\n",
    "    all_scores.append(scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_time': 0.54, 'end_time': '1.03', 'sentence': 'Hi.', 'min_confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check!\n",
    "print(all_sentences_and_times[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_scores_list = [item for sublist in all_scores for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the first transcript to a txt file\n",
    "Let's save the full transcript, as we'll be using this later for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "file0 = open(\"originaltranscript.txt\",\"w\") \n",
    "for tup in sentences_and_times_1:\n",
    "    file0.write(tup['sentence'] + \"\\n\") \n",
    "file0.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of confidence scores\n",
    "Let’s take a look at the distribution of confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.xlim([min(scores_1)-0.1, max(scores_1)+0.1])\n",
    "plt.hist(scores_1, bins=20, alpha=0.5)\n",
    "plt.title('Plot of confidence scores')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of low confidence scores\n",
    "Let’s filter out the high confidence scores to take a closer look at the lower ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_scores = [i for i in scores_1 if i < 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim([min(bad_scores)-0.1, 1.0])\n",
    "plt.hist(bad_scores, bins=20, alpha=0.5)\n",
    "plt.title('Plot of confidence scores less than 0.9')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.3\n",
    "all_bad_scores = [i for i in flat_scores_list if i < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.xlim([min(all_bad_scores)-0.1, max(all_bad_scores)+0.1])\n",
    "plt.hist(all_bad_scores, bins=20, alpha=0.5)\n",
    "plt.title('Plot of confidence scores less than ' + str(threshold))\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a nontrivial number of words classified with low confidence. As we’ll see later, technical terms are more often mis-transcribed, so it’s important that we correct those mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Human Review Workflow with A2I\n",
    "\n",
    "Our next step is create a human review workflow that sends low confidence scores to human reviewers and then retrieves the corrected transcription they provide. This section contains the following steps:\n",
    "\n",
    "1. Create a work task template that will be displayed to workers for every task. The template will be rendered with input data you provide, instructions to workers, and interactive tools to help workers complete your tasks.\n",
    "2. Create a human review workflow, also called a flow definition. You use the flow definition to configure details about your human workforce and the human tasks they are assigned.\n",
    "3. Create a human loop to start the human review workflow, sending data for human review as needed. In this example, you use a custom task type and start human loop tasks using the [Amazon A2I Runtime API](https://docs.aws.amazon.com/augmented-ai/2019-11-07/APIReference/Welcome.html). Each time StartHumanLoop is called, a task is sent to human reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workteam or Workforce\n",
    "\n",
    "\n",
    "A workforce is the group of workers that you have selected to label your dataset. You can choose either the Amazon Mechanical Turk workforce, a vendor-managed workforce, or you can create your own private workforce for human reviews. Whichever workforce type you choose, Amazon Augmented AI takes care of sending tasks to workers.\n",
    "\n",
    "When you use a private workforce, you also create work teams, a group of workers from your workforce that are assigned to Amazon Augmented AI human review tasks. You can have multiple work teams and can assign one or more work teams to each job.\n",
    "\n",
    "To create your Workteam, visit the instructions [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management.html)\n",
    "\n",
    "After you have created your workteam, replace YOUR_WORKTEAM_ARN below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN= \"arn:aws:sagemaker:us-west-2:688520471316:workteam/private-crowd/jashuang-test-workforce\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients\n",
    "Let's setup the rest of our clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker = boto3.client('sagemaker', region)\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "s3 = boto3.client('s3', region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Control Plane Resources\n",
    "Now let's create the resources we'll need to build our human review workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Human Task UI\n",
    "\n",
    "Amazon A2I uses Liquid, an open-source template language that can be used to “inject” data dynamically into HTML files.\n",
    "\n",
    "In this walkthrough, we want for each task to enable a human reviewer to watch a section of the video and transcribe the speech they hear. The HTML template consists of three main parts:\n",
    "\n",
    "1. A video player with a replay button that only allows the reviewer to play the specific subsection\n",
    "2. A form for the reviewer to type and submit what they hear\n",
    "3. Logic written in JavaScript to give the replay button its intended functionality\n",
    "\n",
    "For over 60 other pre-built UIs, check out this [repository](https://github.com/aws-samples/amazon-a2i-sample-task-uis).\n",
    "\n",
    "Here’s the template you’ll be using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r\"\"\"\n",
    "<head>\n",
    "    <style>\n",
    "        h1 {\n",
    "            color: black;\n",
    "            font-family: verdana;\n",
    "            font-size: 150%;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "    <video id=\"this_vid\">\n",
    "        <source src=\"{{ task.input.audioPath | grant_read_access }}\"\n",
    "            type=\"audio/mp4\">\n",
    "        Your browser does not support the audio element.\n",
    "    </video>\n",
    "    <br />\n",
    "    <br />\n",
    "    <crowd-button onclick=\"onClick(); return false;\"><h1> Click to play video section!</h1></crowd-button> \n",
    "\n",
    "    <h3>Instructions</h3>\n",
    "    <p>Transcribe the audio clip </p>\n",
    "    <p>Ignore \"umms\", \"hmms\", \"uhs\" and other non-textual phrases. </p>\n",
    "    <p>The original transcript is <strong>\"{{ task.input.original_words }}\"</strong>. If the text matches the audio, please retype the same transcription.</p>\n",
    "    <p>Click the space below to start typing.</p>\n",
    "    <crowd-text-area name=\"transcription\" rows=\"2\" label=\"Your transcription\" placeholder=\"Please enter the transcribed text.\"></crowd-text-area>\n",
    "\n",
    "    <full-instructions header=\"Transcription Instructions\">\n",
    "        <h2>Instructions</h2>\n",
    "        <p>Click the play button and listen carefully to the audio clip. Type what you hear in the box\n",
    "            below. Replay the clip by clicking the button again, as many times as needed.</p>\n",
    "    </full-instructions>\n",
    "\n",
    "</crowd-form>\n",
    "\n",
    "<script>\n",
    "    var video = document.getElementById('this_vid');\n",
    "    video.onloadedmetadata = function() {\n",
    "        video.currentTime = {{ task.input.start_time }};\n",
    "    };\n",
    "    function onClick() {\n",
    "        video.pause();\n",
    "        video.currentTime = {{ task.input.start_time }};\n",
    "        video.play();\n",
    "        video.ontimeupdate = function () {\n",
    "            if (video.currentTime >= {{ task.input.end_time }}) {\n",
    "                video.pause()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "#t={{ task.input.start_time }},{{ task.input.end_time }}\n",
    "\n",
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `{{ task.input.audioPath | grant_read_access }}` field allows you to grant access to and display a video using a path to the video’s location in an S3 bucket. To prevent the reviewer from navigating to irrelevant sections of the video, the `controls` parameter is omitted from the video tag and a single replay button is included to control which section can be replayed.\n",
    "\n",
    "Below the video player, the `<crowd-text-area>` HTML tag creates a submission form that your reviewer will use to type and submit.\n",
    "\n",
    "At the end of the HTML snippet, the `<script>` tag contains the logic for the replay button. The `{{ task.input.start_time }}` and `{{ task.input.end_time }}` fields allow you to inject the start and end times of the video subsection you want transcribed for the current task.\n",
    "\n",
    "Now let's create a Human Task UI resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'ui-transcribe-' + str(uuid.uuid4()) \n",
    "\n",
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Definition\n",
    "\n",
    "In this section, we're going to create a flow definition definition. Flow Definitions allow us to specify:\n",
    "\n",
    "* The workforce that your tasks will be sent to.\n",
    "* The instructions that your workforce will receive. This is called a worker task template.\n",
    "* The configuration of your worker tasks, including the number of workers that receive a task and time limits to complete tasks.\n",
    "* Where your output data will be stored.\n",
    "\n",
    "This demo is going to use the API, but you can optionally create this workflow definition in the console as well.\n",
    "\n",
    "For more details and instructions, see [here](https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'fd-transcribe-demo-' + str(uuid.uuid4()) \n",
    "\n",
    "create_workflow_definition_response = sagemaker.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn= ROLE,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Identify the word(s) spoken in the provided audio clip\",\n",
    "            \"TaskTitle\": \"Determine Words/Phrases of Audio Clip\"\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe flow definition - status should be active\n",
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Loops\n",
    "### Sending sequences of words/phrases of low confidence for review\n",
    "After setting up our Flow Definition, we're ready to use Amazon Transcribe and initiate human loops. While iterating through the list of transcribed words and their confidence scores, we create a HumanLoop task whenever the confidence score is below some threshold, `CONFIDENCE_SCORE_THRESHOLD`.\n",
    "\n",
    "An important thing to consider is how do we deal with a low-confidence word that is part of a phrase that was also mis-transcribed? To handle these cases, let’s write a function that gets the sequence of words centered about a given index, and the sequence's starting and ending timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to get the words near a word with poor confidence,\n",
    "# since it is possible that the transcription also mis-transcribed nearby words/phrases\n",
    "def get_word_neighbors(words, index):\n",
    "    \"\"\"\n",
    "    gets the words transcribe found at most 3 away from the input index\n",
    "    Returns:\n",
    "        list: words at most 3 away from the input index\n",
    "        int: starting time of the first word in the list\n",
    "        int: ending time of the last word in the list\n",
    "    \"\"\"\n",
    "    i = max(0, index - 3)\n",
    "    j = min(len(words) - 1, index + 3)\n",
    "    return words[i: j + 1], words[i][\"start_time\"], words[j][\"end_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for every word we encounter with low confidence, we send its associated sequence of neighboring words for human review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data, human loop started\n",
    "human_loops_started = []\n",
    "CONFIDENCE_SCORE_THRESHOLD = .4\n",
    "i = 0\n",
    "for obj in confidences_1:\n",
    "    word = obj[\"content\"]\n",
    "    neighbors, start_time, end_time = get_word_neighbors(confidences_1, i)\n",
    "    \n",
    "    # Our condition for when we want to engage a human for review\n",
    "    if (obj[\"confidence\"] < CONFIDENCE_SCORE_THRESHOLD):\n",
    "        \n",
    "        # get the original sequence of words\n",
    "        sequence = \"\"\n",
    "        for block in neighbors:\n",
    "            sequence += block['content'] + \" \"\n",
    "        \n",
    "        humanLoopName = str(uuid.uuid4())\n",
    "        # \"initialValue\": word,\n",
    "        inputContent = {\n",
    "            \"audioPath\": job_uri_s3,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"original_words\": sequence\n",
    "        }\n",
    "        start_loop_response = a2i.start_human_loop(\n",
    "            HumanLoopName=humanLoopName,\n",
    "            FlowDefinitionArn=flowDefinitionArn,\n",
    "            HumanLoopInput={\n",
    "                \"InputContent\": json.dumps(inputContent)\n",
    "            }\n",
    "        )\n",
    "        human_loops_started.append(humanLoopName)\n",
    "        print(f'Confidence score of {obj[\"confidence\"]} is less than the threshold of {CONFIDENCE_SCORE_THRESHOLD}')\n",
    "        print(f'Starting human loop with name: {humanLoopName}')\n",
    "        print(f'Sending words from times {start_time} to {end_time} to review')\n",
    "        print(f'The original transcription is \"\"{sequence}\"\" \\n')\n",
    "#     else:\n",
    "# #         print(f'SentimentScore of {obj[\"confidence\"]} is above threshold of {CONFIDENCE_SCORE_THRESHOLD}')\n",
    "# #         print('No human loop created. \\n')\n",
    "\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save the name of each human loop, in case we need to retrieve them later after shutting down this notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hl = open(\"human_loops_names.txt\",\"w\") \n",
    "for name in human_loops_started:\n",
    "    file_hl.write(name + \"\\n\") \n",
    "file_hl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f'HumanLoop Name: {human_loop_name}')\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait For Workers to Complete Task\n",
    "We display the link to the private worker portal here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait For Workers to Complete Task\n",
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f'HumanLoop Name: {human_loop_name}')\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Task Results\n",
    "\n",
    "Once work is completed, Amazon A2I stores results in your S3 bucket and sends a Cloudwatch event. Your results should be available in the S3 `OUTPUT_PATH` when all work is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Custom vocabularies using A2I results\n",
    "\n",
    "Using the corrected transcriptions from our human reviewers, let’s parse through these results to identify the domain-specific terms that we want to add to a custom vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve A2I results\n",
    "To get the technical terms identified by human review, we first accumulate all human-reviewed words into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_words = []\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    \n",
    "    # add the human-reviewed answers split by spaces\n",
    "    corrected_words += json_output['humanAnswers'][0]['answerContent']['transcription'].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out common English words\n",
    "Now, we want to parse through these words and look for “uncommon” English words. An easy way to do this is to use a large English corpus and verify whether each of our human-reviewed words exists in this corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of English words\n",
    "# Note that this corpus of words is not 100% exhaustive\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "my_dict=set(words.words()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing contractions\n",
    "# https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "def remove_contractions(word_list):\n",
    "    return [word for word in word_list if word not in contractions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Technical/Uncommon Words\n",
    "After removing contractions, human-reviewed words that are not in the English language corpus are likely to be the technical terms we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in remove_contractions(corrected_words):\n",
    "    if word not in my_dict:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Vocabulary\n",
    "Using the technical terms identified above, we manually created a custom vocabulary of those terms that we want Transcribe to be able to recognize. A custom vocabulary table enables options to tell Amazon Transcribe how each technical term is pronounced and how it should be displayed.\n",
    "\n",
    "More details on how to form a custom vocabulary table can be found [here](https://docs.aws.amazon.com/transcribe/latest/dg/how-vocabulary.html#create-vocabulary-table)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as you process additional videos on the same topic, you can keep updating this list, and the number of new technical terms you'll have to add will likely decrease each time you get a new video.\n",
    "\n",
    "TODO: update this list for comprehensive vocab after doing entire video analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_words=[['Phrase','IPA','SoundsLike','DisplayAs'], # This top line denote the column headers of the text file.\n",
    "                 ['E.C.-Two','','ee-see-too','EC2'],\n",
    "                 ['E.C.-Two-instance','','ee-see-too-in-stunce','EC2 instance'],\n",
    "                 ['lambda','','lam-duh','Lambda'],\n",
    "                 ['S.D.K.','','ess-dee-kay','SDK'],\n",
    "                 ['boto-three','','boe-toe-three','Boto3'],\n",
    "                 ['S.-Three','','ess-three','S3'],\n",
    "                 ['github','','git-hub','Github'],\n",
    "                 ['sagemaker','','sage-may-ker','SageMaker'],\n",
    "                 ['E.B.S.','','ee-bee-ess','EBS'],\n",
    "                 ['G.P.U.','','gee-pee-you','GPU'],\n",
    "                 ['git-repository','','git-ree-paw-zih-tor-ee','Git repository'],\n",
    "                 ['jupyter','','joo-pih-ter','Jupyter'],\n",
    "                 ['kernel','','ker-null','kernel'],\n",
    "                 ['config','','con-fig','config'],\n",
    "                 ['configs','','con-figs','configs'],\n",
    "                 ['D.B.-pedia','','dee-bee-pee-dee-yuh','dbpedia'],\n",
    "                 ['git-clone','','','git clone'],\n",
    "                 ['notebook-instance','','','notebook instance'],\n",
    "                 ['V.P.C.','','','VPC'],\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Table to a Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vocab_file_name = \"customvocab3.txt\"\n",
    "file1 = open(custom_vocab_file,\"w\")\n",
    "template = '{}\\t{}\\t{}\\t{}\\n'\n",
    "for line in finalized_words:\n",
    "    file1.write(template.format(line[0],\n",
    "                                line[1],\n",
    "                                line[2],\n",
    "                                line[3])\n",
    "               )\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Custom Vocabulary File to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file(custom_vocab_file_name, BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Custom Vocabulary\n",
    "After saving your custom vocabulary table to a text file and uploading it to an S3 bucket, create your custom vocabulary with a specified name so that Amazon Transcribe can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_improved='aws-sagemaker-vocab-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client(\"transcribe\")\n",
    "response = transcribe.create_vocabulary(\n",
    "    VocabularyName=vocab_improved,\n",
    "    LanguageCode='en-US',\n",
    "    VocabularyFileUri='s3://' + BUCKET + '/' + custom_vocab_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the status of the vocab you created again (must wait until its VocabularyState is READY)\n",
    "response2 = transcribe.get_vocabulary(\n",
    "    VocabularyName=vocab_improved\n",
    ")\n",
    "pp.pprint(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improved Transcription using your Custom Vocabulary\n",
    "\n",
    "### Re-transcribe using the Custom Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another job name\n",
    "job_name_2='AWS-sage-improved-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start another transcription job using your custom vocabulary.\n",
    "transcribe(job_name_2, job_uri_s3, BUCKET, vocab_name=vocab_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_transcript_2,sentences_and_times_2, confidences_2, scores_2 = get_transcript_text_and_timestamps(BUCKET,\n",
    "                                                                                                      job_name_2+\".json\")\n",
    "                                                                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Improved Transcript to Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the improved transcript\n",
    "file4 = open(\"improvedtranscript_2.txt\",\"w\") \n",
    "for tup in sentences_and_times_2:\n",
    "    file4.write(tup['sentence'] + \"\\n\") \n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have two transcript versions — one using default parameters and one using our custom vocabulary. To compare these two transcripts, the last thing we need is a “ground truth” transcript, i.e., an answer key. For this demo, we’ve created a ground truth transcript for the first 5 minutes of the SageMaker video, which you can find in the Github repository.\n",
    "\n",
    "### Calculating Word Error Rate (WER)\n",
    "The most common metric for speech recognition accuracy is called word error rate (WER), which can be roughly defined to be the proportion of transcription errors relative to the number of words that were actually said. More details can be found here (https://en.wikipedia.org/wiki/Word_error_rate).\n",
    "\n",
    "We'll be using a lightweight open-source Python library called JiWER for calculating WER between transcripts.\n",
    "\n",
    "For more details, see the open-source [description](https://pypi.org/project/jiwer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small example\n",
    "ground_truth = \"hello world\"\n",
    "hypothesis = \"hello duck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer(ground_truth, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformation function to preprocess transcript\n",
    "transformation = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.RemoveWhiteSpace(replace_by_space=True),\n",
    "    jiwer.SentencesToListOfWords(),\n",
    "    jiwer.SentencesToListOfWords(word_delimiter=\" \"),\n",
    "    jiwer.RemoveEmptyStrings()\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the original transcript (before applying the custom vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_2_original = \"\"\n",
    "f3 = open(\"originaltranscript.txt\", \"r\")\n",
    "for line in f3:\n",
    "    if line.strip() == \"--STOP--\":\n",
    "        break\n",
    "    hypothesis_2_original += (line.strip() + \" \")\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the new transcript (after applying the custom vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_2 = \"\"\n",
    "f2 = open(\"improvedtranscript_2.txt\", \"r\")\n",
    "for line in f2:\n",
    "    if line.strip() == \"--STOP--\":\n",
    "        break\n",
    "    hypothesis_2 += (line.strip() + \" \")\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the \"Ground Truth\" transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_2 = \"\"\n",
    "f1 = open(\"ground_truth.txt\", \"r\")\n",
    "for line in f1:\n",
    "    if line.strip() == \"--STOP--\":\n",
    "        break\n",
    "    ground_truth_2 += (line.strip() + \" \")\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiwer.wer(\n",
    "    ground_truth_2, \n",
    "    hypothesis_2_original, \n",
    "    truth_transform=transformation, \n",
    "    hypothesis_transform=transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute New Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiwer.wer(\n",
    "    ground_truth_2, \n",
    "    hypothesis_2, \n",
    "    truth_transform=transformation, \n",
    "    hypothesis_transform=transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "For the first 5 minutes of the SageMaker video we used for this demo, the WER decreased from 9.4% to 3.1%, or over 60% improvement.\n",
    "\n",
    "At second glance, the initial WER of 9.4% might already feel sufficiently low — less than 1 in 10 words are mis-transcribed! However, this rate can be misleading, since domain-specific terms are often the least common words spoken (relative to frequent words like “to,” “and,” “I” etc.) but the most commonly mis-transcribed. For applications like search engine optimization (SEO), it could be critical that these technical terms are transcribed correctly. Let’s take a look at how our custom vocabulary impacted the transcription of several important technical terms:\n",
    "\n",
    "TODO: complete full analysis on entire video to update the above metrics and the chart below\n",
    "\n",
    "| Technical Term | Ground Truth mentions | Default Transcript mentions | Custom Vocab Transcript mentions |\n",
    "|----------------|-----------------------|-----------------------------|----------------------------------|\n",
    "| SageMaker      | 7                     | 1 (14%)                     | 7 (100%)                         |\n",
    "| EC2            | 12                    | 0 (0%)                      | 12 (100%)                        |\n",
    "| EBS            | 7                     | 3 (43%)                     | 6 (86%)                          |\n",
    "\n",
    "Now it does look like custom vocabularies were worth the effort!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up\n",
    "To avoid incurring unnecessary charges, delete resources when not in use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In this post, we walked through an example of how you can improve transcripts from Amazon Transcribe using custom vocabularies and an Amazon A2I human review workflow. This allows you to quickly identify domain-specific terms using your own private workforce and review workflows, and use these terms to build a custom vocabulary so that future mentions of term are transcribed with greater accuracy, at scale. Transcribing key technical terms correctly can be important for doing SEO, enabling highly specific textual queries, and grouping large quantities of video or audio files by technical terms.\n",
    "\n",
    "The full proof-of-concept Jupyter notebook can be found at this Github repository. Check out other blog posts covering integrations of Amazon A2I, such as [Using Amazon Textract with Amazon Augmented AI for processing critical documents](https://aws.amazon.com/blogs/machine-learning/using-amazon-textract-with-amazon-augmented-ai-for-processing-critical-documents/) and [Designing human review workflows with Amazon Translate and Amazon Augmented AI](https://aws.amazon.com/blogs/machine-learning/designing-human-review-workflows-with-amazon-translate-and-amazon-augmented-ai/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End!\n",
    "For a more detailed discussion with visuals, check out the accompanying blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
