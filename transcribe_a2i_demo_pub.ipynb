{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Amazon Transcribe transcriptions using Custom Vocabularies and Amazon Augmented AI (A2I)\n",
    "\n",
    "\n",
    "\n",
    "This notebook accompanies the blog \"Improving Amazon Transcribe transcriptions using Custom Vocabularies and Amazon Augmented AI (A2I)\" (TODO: add link)\n",
    "\n",
    "## Introduction\n",
    "When transcribing speech containing domain-specific terminologies in fields such as legal, financial, construction, higher education, or engineering, Amazon Transcribe’s [custom vocabularies](https://docs.aws.amazon.com/transcribe/latest/dg/how-vocabulary.html) feature can improve transcription quality, especially on key technical terms. \n",
    "\n",
    "To use custom vocabularies with Amazon Transcribe, you need a list of domain-specific terms. Using a collection of videos or audio files (i.e., your dataset) that you want transcribed with high accuracy, you can send a portion of your dataset to Amazon Transcribe to identify terms it has difficulty with, indicated by low-confidence scores. You can use Amazon A2I to send these low-confidence predictions directly to a human to manually review and transcribe the terms. This walkthrough will demonstrate how you can process the results obtained from Amazon A2I to quickly to build a custom vocabulary, at scale.\n",
    "\n",
    "In summary, in this walkthrough you will:\n",
    "* Send a subset of videos to Amazon Transcribe to find terms that are difficult to transcribe.\n",
    "* Set up a human review workflow using Amazon A2I to send low-confidence predictions to your human workforce for manual review and transcription.\n",
    "* Create a custom vocabulary using the results obtained from human workers.\n",
    "* Test Amazon Transcribe on another subset of videos to assess the improvement in transcription quality. \n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook, you can simply execute each cell in order. Before beginning, you'll need:\n",
    "\n",
    "* An AWS account.\n",
    "* An S3 bucket you can write to -- please provide its name in BUCKET. The bucket must be in the same region as this SageMaker Notebook instance. You can also change the EXP_NAME to any valid S3 prefix. All the files involved in this demo will be stored in that prefix of your bucket.\n",
    "\n",
    "To help understand this demo, the following are also recommended:\n",
    "* Familiarity with the Amazon A2I.\n",
    "* Familiarity with Python and numpy.\n",
    "* Basic familiarity with AWS S3.\n",
    "* Basic understanding of Amazon Transcribe and custom vocabularies. \n",
    "* Basic familiarity with AWS Command Line Interface (CLI) -- ideally, you should have it set up with credentials to access the AWS account you're running this notebook from.\n",
    "\n",
    "This notebook has been tested on a SageMaker notebook instance. The runtimes given are approximated on an ml.t2.medium instance. You can run it on a local instance by first executing the cell below on SageMaker and then copying the name of the role to your local copy of the notebook.\n",
    "\n",
    "For more sample notebooks using A2I, visit this [Github repository](https://github.com/aws-samples/amazon-a2i-sample-jupyter-notebooks).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Latest SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (20.1.1)\n",
      "Requirement already up-to-date: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.5->boto3) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.5->boto3) (1.11.0)\n",
      "Requirement already up-to-date: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 --upgrade\n",
    "!pip install -U botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import uuid\n",
    "import botocore\n",
    "import boto3\n",
    "import time\n",
    "import pprint\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region, Bucket, and Paths\n",
    "Make sure all your resources are stored in the same region. You'll be using the same bucket for this entire walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'jashuang-sagemaker-5-22'\n",
    "EXP_NAME = '' # Any valid S3 prefix.\n",
    "OUTPUT_PATH = f's3://{BUCKET}/a2i-results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "# Amazon S3 (S3) client\n",
    "s3 = boto3.client('s3', region)\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "assert bucket_region == region, \"Your S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# Amazon Transcribe client\n",
    "transcribe_client = boto3.client(\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roles and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following policies to this role in IAM:\n",
    "* AmazonAugmentedAIFullAccess\n",
    "* AmazonTranscribeFullAccess\n",
    "\n",
    "Or you can add a single policy, which will grant permissions to Amazon A2I and all integrated services (Amazon Rekognition and Amazon Transcribe)\n",
    "* AmazonAugmentedAIIntegratedAPIAccess\n",
    "\n",
    "Your execution role has the AmazonSageMakerFullAccess policy attached. This gives Amazon SageMaker permission to access your resources in S3 if the bucket or objects have the word `sagemaker` in the name. If your S3 bucket listed in `BUCKET` does not have sagemaker in the name, you will need to add an S3 policy to your execution role to give your role permissions to access your data objects in S3. The following is an example of an S3 policy:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::my_input_bucket/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::my_output_bucket/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::688520471316:role/service-role/AmazonSageMaker-ExecutionRole-20200522T134110'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "ROLE = get_execution_role()\n",
    "display(ROLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Sample Video to S3\n",
    "For this demo, we'll be analyzing videos on getting started with Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./a2i_transcribe_test’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./a2i_transcribe_test\n",
    "!aws s3 sync s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/transcribe-notebook-demo/ ./a2i_transcribe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: a2i_transcribe_test/Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4 to s3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$BUCKET\"\n",
    "aws s3 cp ./a2i_transcribe_test/ s3://$1/a2i_transcribe_demo/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS-sage-vid-0-18.33.51']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can give each transcription job any name. We attach a timestamp to each job name here\n",
    "# to prevent conflicting job names in case we need to re-run any jobs.\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%H.%M.%S\")\n",
    "\n",
    "job_names = []\n",
    "for i in range(1):\n",
    "    job_names.append(\"AWS-sage-vid-\" + str(i) + \"-\" + str(time_now))\n",
    "\n",
    "# Path to folder\n",
    "folder_path = f\"s3://{BUCKET}/a2i_transcribe_demo/\"\n",
    "\n",
    "# Names of the video titles. If you want to test more videos, uncomment them below.\n",
    "all_videos = [\n",
    "             'Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4',\n",
    "#              'Built-in Machine Learning Algorithms with Amazon SageMaker - a Deep Dive.mp4',\n",
    "#              'Bring Your Own Custom ML Models with Amazon SageMaker.mp4',\n",
    "#              'Train Your ML Models Accurately with Amazon SageMaker.mp4',\n",
    "#              'Deploy Your ML Models to Production at Scale with Amazon SageMaker.mp4',\n",
    "#              'Tune Your ML Models to the Highest Accuracy with Amazon SageMaker Automatic Model Tuning.mp4',\n",
    "#              'Scale up Training of Your ML Models with Distributed Training on Amazon SageMaker.mp4',\n",
    "#              'Use the Deep Learning Framework of Your Choice with Amazon SageMaker.mp4',\n",
    "#              'Learn to Analyze the Co-Relation in Your Datasets Using Feature Engineering with Amazon SageMake.mp4',\n",
    "#              'Get Scheduled Predictions on Your ML Models with Amazon SageMaker Batch Transform.mp4'\n",
    "]\n",
    "\n",
    "job_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Basic Transcription Job\n",
    "Our first step is to look at the performance of Amazon Transcribe using default parameters and establish a baseline for comparison. Once you have the SageMaker video mp4 file uploaded to an S3 bucket, you can use the transcribe function to start a transcription job. Note that the `vocab_name` parameter will be used later to specify custom vocabularies, and it’s currently defaulted to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this demo, we'll be transcribing the first video in the playlist. Feel free to experiment with additional videos we've provided, or your own content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a transcribe function\n",
    "def transcribe(job_name, job_uri, out_bucket, format=\"mp4\", vocab_name=None):\n",
    "    \"\"\"Transcribe a .wav or .mp4 file to text.\n",
    "    Args:\n",
    "        job_name (str): the name of the job that you specify;\n",
    "                        the output json will be job_name.json\n",
    "        job_uri (str): input path (in s3) to the file being transcribed\n",
    "        out_bucket (str): s3 bucket name that you want the output json\n",
    "                          to be placed in\n",
    "        format (str): mp4 or wav for input file format;\n",
    "                      defaults to mp4\n",
    "        vocab_name (str): name of custom vocabulary used;\n",
    "                          optional, defaults to None\n",
    "    \"\"\"\n",
    "    \n",
    "    if format not in ['mp3','mp4','wav','flac']:\n",
    "        print(\"Invalid format\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(\"------\" + format)\n",
    "        if vocab_name is None:\n",
    "            transcribe_client.start_transcription_job(\n",
    "                TranscriptionJobName=job_name,\n",
    "                Media={\"MediaFileUri\": job_uri},\n",
    "                MediaFormat=format,\n",
    "                LanguageCode=\"en-US\",\n",
    "                OutputBucketName=out_bucket,\n",
    "            )\n",
    "        else:\n",
    "            transcribe_client.start_transcription_job(\n",
    "                TranscriptionJobName=job_name,\n",
    "                Media={\"MediaFileUri\": job_uri},\n",
    "                MediaFormat=format,\n",
    "                LanguageCode=\"en-US\",\n",
    "                OutputBucketName=out_bucket,\n",
    "                Settings={'VocabularyName': vocab_name}\n",
    "            )\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(transcribe_client.get_transcription_job(TranscriptionJobName=job_name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------mp4\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'AWS-sage-vid-0-18.33.51', 'TranscriptionJobStatus': 'IN_PROGRESS', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp4', 'Media': {'MediaFileUri': 's3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4'}, 'Transcript': {}, 'StartTime': datetime.datetime(2020, 6, 18, 18, 34, 23, 360000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 6, 18, 18, 34, 23, 338000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '2fba2be0-fe97-4488-a0a9-7b71963f005e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Thu, 18 Jun 2020 18:34:25 GMT', 'x-amzn-requestid': '2fba2be0-fe97-4488-a0a9-7b71963f005e', 'content-length': '475', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# # Start a transcription job\n",
    "transcribe(job_names[0], folder_path+all_videos[0], BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check transcription job statuses\n",
    "\n",
    "Wait until the status displays `COMPLETED` before moving on to the next cells. A transcription job for a 10-15 minute video typically takes roughly 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "for job_name in job_names:\n",
    "    print(transcribe_client.get_transcription_job(TranscriptionJobName=job_name)['TranscriptionJob']['TranscriptionJobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Parse Transcription Results\n",
    "\n",
    "When the transcription job finishes, the results will be stored in your specified S3 bucket as an output JSON file called “YOUR_JOB_NAME.json.” You can use the following function to retrieve your results, and parse them into sentences with time stamps, confidence scores, and other useful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_text_and_timestamps(bucket_name, file_name):\n",
    "    \"\"\"take json file from S3 bucket and returns a tuple of:\n",
    "       entire transcript, list object of tuples of timestamp and individual sentences\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): name of s3 bucket\n",
    "        file_name (str): name of file\n",
    "    Returns:\n",
    "        (\n",
    "        entire_transcript: str,\n",
    "        sentences_and_times: [ {start_time (sec) : float,\n",
    "                                end_time (sec)   : float,\n",
    "                                sentence         : str,\n",
    "                                min_confidence   : float (minimum confidence score of that sentence)\n",
    "                                } ],\n",
    "        confidences:  [ {start_time (sec) : float,\n",
    "                         end_time (sec)   : float,\n",
    "                         content          : str, (single word/phrase)\n",
    "                         confidence       : float (confidence score of the word/phrase)\n",
    "                         } ],\n",
    "        scores: list of confidence scores\n",
    "        )\n",
    "    \"\"\"\n",
    "    s3_clientobj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    original = json.loads(s3_clientdata)\n",
    "    items = original[\"results\"][\"items\"]\n",
    "    entire_transcript = original[\"results\"][\"transcripts\"]\n",
    "\n",
    "    sentences_and_times = []\n",
    "    temp_sentence = \"\"\n",
    "    temp_start_time = 0\n",
    "    temp_min_confidence = 1.0\n",
    "    newSentence = True\n",
    "    \n",
    "    confidences = []\n",
    "    scores = []\n",
    "\n",
    "    i = 0\n",
    "    for item in items:\n",
    "        # always add the word\n",
    "        if item[\"type\"] == \"punctuation\":\n",
    "            temp_sentence = (\n",
    "                temp_sentence.strip() + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            )\n",
    "        else:\n",
    "            temp_sentence = temp_sentence + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            temp_min_confidence = min(temp_min_confidence,\n",
    "                                      float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "            confidences.append({\"start_time\": float(item[\"start_time\"]),\n",
    "                                \"end_time\": float(item[\"end_time\"]),\n",
    "                                \"content\": item[\"alternatives\"][0][\"content\"],\n",
    "                                \"confidence\": float(item[\"alternatives\"][0][\"confidence\"])\n",
    "                               })\n",
    "            scores.append(float(item[\"alternatives\"][0][\"confidence\"]))\n",
    "\n",
    "        # if this is a new sentence, and it starts with a word, save the time\n",
    "        if newSentence == True:\n",
    "            if item[\"type\"] == \"pronunciation\":\n",
    "                temp_start_time = float(item[\"start_time\"])\n",
    "            newSentence = False\n",
    "        # else, keep going until you hit a punctuation\n",
    "        else:\n",
    "            if (\n",
    "                item[\"type\"] == \"punctuation\"\n",
    "                and item[\"alternatives\"][0][\"content\"] != \",\"\n",
    "            ):\n",
    "                # end time of sentence is end_time of previous word\n",
    "                end_time = items[i-1][\"end_time\"] if i-1 >= 0 else items[0][\"end_time\"]\n",
    "                sentences_and_times.append(\n",
    "                    {\"start_time\": temp_start_time,\n",
    "                     \"end_time\": end_time,\n",
    "                     \"sentence\": temp_sentence.strip(),\n",
    "                     \"min_confidence\": temp_min_confidence\n",
    "                    }\n",
    "                )\n",
    "                # reset the temp sentence and relevant variables\n",
    "                newSentence = True\n",
    "                temp_sentence = \"\"\n",
    "                temp_min_confidence = 1.0\n",
    "                \n",
    "        i = i + 1\n",
    "        \n",
    "    sentences_and_times.append(\n",
    "                    {\"start_time\": temp_start_time,\n",
    "                     \"end_time\": confidences[-1][\"end_time\"],\n",
    "                     \"sentence\": temp_sentence.strip(),\n",
    "                     \"min_confidence\": temp_min_confidence\n",
    "                    }\n",
    "                )\n",
    "    return entire_transcript, sentences_and_times, confidences, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Parsing AWS-sage-vid-0-18.33.51.json\n"
     ]
    }
   ],
   "source": [
    "all_entire_transcript = []\n",
    "all_sentences_and_times = []\n",
    "all_confidences = []\n",
    "all_scores = []\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    print(f\"Parsing {job_names[i]}.json\")\n",
    "    entire_transcript_1, sentences_and_times_1, confidences_1, scores_1 = get_transcript_text_and_timestamps(BUCKET,job_names[i]+\".json\")\n",
    "    all_entire_transcript.append(entire_transcript_1)\n",
    "    all_sentences_and_times.append(sentences_and_times_1)\n",
    "    all_confidences.append(confidences_1)\n",
    "    all_scores.append(scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_time': 0.54, 'end_time': '1.03', 'sentence': 'Hi.', 'min_confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check!\n",
    "print(all_sentences_and_times[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the original transcripts to txt files\n",
    "Let's save the full transcripts, as we'll be using this later for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for sentences_times in all_sentences_and_times:\n",
    "    file0 = open(f\"original_transcript_{i}.txt\",\"w\") \n",
    "    for tup in sentences_times:\n",
    "        file0.write(tup['sentence'] + \"\\n\") \n",
    "    file0.close()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of confidence scores\n",
    "Let’s take a look at the distribution of confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "flat_scores_list = all_scores[0]\n",
    "\n",
    "plt.xlim([min(flat_scores_list)-0.1, max(flat_scores_list)+0.1])\n",
    "plt.hist(flat_scores_list, bins=20, alpha=0.5)\n",
    "plt.title('Plot of confidence scores')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of low confidence scores\n",
    "Let’s filter out the high confidence scores to take a closer look at the lower ones.\n",
    "You can experiment with different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 words that have confidence score less than 0.3\n"
     ]
    }
   ],
   "source": [
    "all_bad_scores = [i for i in flat_scores_list if i < THRESHOLD]\n",
    "print(f\"There are {len(all_bad_scores)} words that have confidence score less than {THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim([min(all_bad_scores)-0.1, max(all_bad_scores)+0.1])\n",
    "plt.hist(all_bad_scores, bins=20, alpha=0.5)\n",
    "plt.title(f'Plot of confidence scores less than {THRESHOLD}')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a nontrivial number of words classified with low confidence. As we’ll see later, technical terms are more often mis-transcribed, so it’s important that we correct those mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Human Review Workflow with A2I\n",
    "\n",
    "Our next step is create a human review workflow that sends low confidence scores to human reviewers and then retrieves the corrected transcription they provide. This section contains the following steps:\n",
    "\n",
    "1. Create a work task template that will be displayed to workers for every task. The template will be rendered with input data you provide, instructions to workers, and interactive tools to help workers complete your tasks.\n",
    "2. Create a human review workflow, also called a flow definition. You use the flow definition to configure details about your human workforce and the human tasks they are assigned.\n",
    "3. Create a human loop to start the human review workflow, sending data for human review as needed. In this example, you use a custom task type and start human loop tasks using the [Amazon A2I Runtime API](https://docs.aws.amazon.com/augmented-ai/2019-11-07/APIReference/Welcome.html). Each time StartHumanLoop is called, a task is sent to human reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workteam or Workforce\n",
    "\n",
    "\n",
    "A workforce is the group of workers that you have selected to label your dataset. You can choose either the Amazon Mechanical Turk workforce, a vendor-managed workforce, or you can create your own private workforce for human reviews. Whichever workforce type you choose, Amazon Augmented AI takes care of sending tasks to workers.\n",
    "\n",
    "When you use a private workforce, you also create work teams, a group of workers from your workforce that are assigned to Amazon Augmented AI human review tasks. You can have multiple work teams and can assign one or more work teams to each job.\n",
    "\n",
    "To create your Workteam, visit the instructions [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management.html).\n",
    "\n",
    "After you have created your workteam, replace YOUR_WORKTEAM_ARN below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN= \"arn:aws:sagemaker:us-west-2:688520471316:workteam/private-crowd/jashuang-test-workforce\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients\n",
    "Let's setup the rest of our clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker = boto3.client('sagemaker', region)\n",
    "\n",
    "# Amazon Augment AI (A2I) client\n",
    "a2i = boto3.client('sagemaker-a2i-runtime')\n",
    "\n",
    "# S3 client\n",
    "s3 = boto3.client('s3', region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Resources for an A2I Human Review\n",
    "Now let's create the resources we'll need to build our human review workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Human Task UI\n",
    "\n",
    "Amazon A2I uses Liquid, an open-source template language that can be used to “inject” data dynamically into HTML files.\n",
    "\n",
    "In this walkthrough, we want for each task to enable a human reviewer to watch a section of the video and transcribe the speech they hear. The HTML template consists of three main parts:\n",
    "\n",
    "1. A video player with a replay button that only allows the reviewer to play the specific subsection\n",
    "2. A form for the reviewer to type and submit what they hear\n",
    "3. Logic written in JavaScript to give the replay button its intended functionality\n",
    "\n",
    "For over 60 other pre-built UIs, check out this [repository](https://github.com/aws-samples/amazon-a2i-sample-task-uis).\n",
    "\n",
    "Here’s the template you’ll be using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r\"\"\"\n",
    "<head>\n",
    "    <style>\n",
    "        h1 {\n",
    "            color: black;\n",
    "            font-family: verdana;\n",
    "            font-size: 150%;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "\n",
    "<crowd-form>\n",
    "    <video id=\"this_vid\">\n",
    "        <source src=\"{{ task.input.audioPath | grant_read_access }}\"\n",
    "            type=\"audio/mp4\">\n",
    "        Your browser does not support the audio element.\n",
    "    </video>\n",
    "    <br />\n",
    "    <br />\n",
    "    <crowd-button onclick=\"onClick(); return false;\"><h1> Click to play video section!</h1></crowd-button>\n",
    "    <br />\n",
    "    Video title: <strong>{{ task.input.video_title }}</strong>\n",
    "    <br />\n",
    "\n",
    "    <h3>Instructions</h3>\n",
    "    <p>Transcribe the audio clip </p>\n",
    "    <p>The original transcript is <strong>\"{{ task.input.original_words }}\"</strong>.\n",
    "    If the text matches the audio, please retype the same transcription.</p>\n",
    "    <p>Ignore \"umms\", \"hmms\", \"uhs\" and other non-textual phrases. </p>\n",
    "    <p><strong>Important:</strong> If you encounter a technical term that has multiple words,\n",
    "    please <strong>hyphenate</strong> those words together. For example, \"k nearest neighbors\" should be transcribed as \"k-nearest-neighbors.\"</p>\n",
    "    <p>Click the space below to start typing.</p>\n",
    "    <crowd-text-area name=\"transcription\" rows=\"2\" label=\"Your transcription\" placeholder=\"Please enter the transcribed text.\"></crowd-text-area>\n",
    "\n",
    "    <full-instructions header=\"Transcription Instructions\">\n",
    "        <h2>Instructions</h2>\n",
    "        <p>Click the play button and listen carefully to the audio clip. Type what you hear in the box\n",
    "            below. Replay the clip by clicking the button again, as many times as needed.</p>\n",
    "    </full-instructions>\n",
    "\n",
    "</crowd-form>\n",
    "\n",
    "<script>\n",
    "    var video = document.getElementById('this_vid');\n",
    "    video.onloadedmetadata = function() {\n",
    "        video.currentTime = {{ task.input.start_time }};\n",
    "    };\n",
    "    function onClick() {\n",
    "        video.pause();\n",
    "        video.currentTime = {{ task.input.start_time }};\n",
    "        video.play();\n",
    "        video.ontimeupdate = function () {\n",
    "            if (video.currentTime >= {{ task.input.end_time }}) {\n",
    "                video.pause()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def create_task_ui():\n",
    "    '''\n",
    "    Creates a Human Task UI resource.\n",
    "\n",
    "    Returns:\n",
    "    struct: HumanTaskUiArn\n",
    "    '''\n",
    "    response = sagemaker.create_human_task_ui(\n",
    "        HumanTaskUiName=taskUIName,\n",
    "        UiTemplate={'Content': template})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `{{ task.input.audioPath | grant_read_access }}` field allows you to grant access to and display a video using a path to the video’s location in an S3 bucket. To prevent the reviewer from navigating to irrelevant sections of the video, the `controls` parameter is omitted from the video tag and a single replay button is included to control which section can be replayed.\n",
    "\n",
    "Below the video player, the `<crowd-text-area>` HTML tag creates a submission form that your reviewer will use to type and submit.\n",
    "\n",
    "At the end of the HTML snippet, the `<script>` tag contains the logic for the replay button. The `{{ task.input.start_time }}` and `{{ task.input.end_time }}` fields allow you to inject the start and end times of the video subsection you want transcribed for the current task.\n",
    "\n",
    "Now let's create a Human Task UI resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-west-2:688520471316:human-task-ui/ui-transcribe-a469adfb-cb0e-4fa3-b0fd-fc36da469d09\n"
     ]
    }
   ],
   "source": [
    "# Task UI name - this value is unique per account and region. You can also provide your own value here.\n",
    "taskUIName = 'ui-transcribe-' + str(uuid.uuid4()) \n",
    "\n",
    "# Create task UI\n",
    "humanTaskUiResponse = create_task_ui()\n",
    "humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n",
    "print(humanTaskUiArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Definition\n",
    "\n",
    "In this section, we're going to create a flow definition definition. Flow Definitions allow us to specify:\n",
    "\n",
    "* The workforce that your tasks will be sent to.\n",
    "* The instructions that your workforce will receive. This is called a worker task template.\n",
    "* The configuration of your worker tasks, including the number of workers that receive a task and time limits to complete tasks.\n",
    "* Where your output data will be stored.\n",
    "\n",
    "This demo is going to use the API, but you can optionally create this workflow definition in the console as well.\n",
    "\n",
    "For more details and instructions, see [here](https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-create-flow-definition.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow definition name - this value is unique per account and region. You can also provide your own value here.\n",
    "flowDefinitionName = 'demo-fd-transcribe-' + str(uuid.uuid4()) \n",
    "\n",
    "create_workflow_definition_response = sagemaker.create_flow_definition(\n",
    "        FlowDefinitionName= flowDefinitionName,\n",
    "        RoleArn= ROLE,\n",
    "        HumanLoopConfig= {\n",
    "            \"WorkteamArn\": WORKTEAM_ARN,\n",
    "            \"HumanTaskUiArn\": humanTaskUiArn,\n",
    "            \"TaskCount\": 1,\n",
    "            \"TaskDescription\": \"Identify the word(s) spoken in the provided audio clip\",\n",
    "            \"TaskTitle\": \"DEMO: Determine Words/Phrases of Audio Clip: \" + str(datetime.now())\n",
    "        },\n",
    "        OutputConfig={\n",
    "            \"S3OutputPath\" : OUTPUT_PATH\n",
    "        }\n",
    "    )\n",
    "flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn'] # let's save this ARN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "Active\n",
      "Flow Definition is active\n"
     ]
    }
   ],
   "source": [
    "# Describe flow definition - status should be active\n",
    "for x in range(60):\n",
    "    describeFlowDefinitionResponse = sagemaker.describe_flow_definition(FlowDefinitionName=flowDefinitionName)\n",
    "    print(describeFlowDefinitionResponse['FlowDefinitionStatus'])\n",
    "    if (describeFlowDefinitionResponse['FlowDefinitionStatus'] == 'Active'):\n",
    "        print(\"Flow Definition is active\")\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Loops\n",
    "### Sending sequences of words/phrases of low confidence for review\n",
    "After setting up our Flow Definition, we're ready to use Amazon Transcribe and initiate human loops. While iterating through the list of transcribed words and their confidence scores, we create a HumanLoop task whenever the confidence score is below some threshold, `CONFIDENCE_SCORE_THRESHOLD`.\n",
    "\n",
    "An important thing to consider is how do we deal with a low-confidence word that is part of a phrase that was also mis-transcribed? To handle these cases, let’s write a function that gets the sequence of words centered about a given index, and the sequence's starting and ending timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to get the words near a word with poor confidence,\n",
    "# since it is possible that the transcription also mis-transcribed nearby words/phrases\n",
    "def get_word_neighbors(words, index):\n",
    "    \"\"\"\n",
    "    gets the words transcribe found at most 3 away from the input index\n",
    "    Returns:\n",
    "        list: words at most 3 away from the input index\n",
    "        int: starting time of the first word in the list\n",
    "        int: ending time of the last word in the list\n",
    "    \"\"\"\n",
    "    i = max(0, index - 3)\n",
    "    j = min(len(words) - 1, index + 3)\n",
    "    return words[i: j + 1], words[i][\"start_time\"], words[j][\"end_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for every word we encounter with low confidence, we send its associated sequence of neighboring words for human review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4 =========\n",
      "The original transcription is \"the Internet s Oh this is from \" \n",
      "\n",
      "The original transcription is \"this is from Sarraf He's the author \" \n",
      "\n",
      "The original transcription is \"right up here then the title of \" \n",
      "\n",
      "The original transcription is \"but definitely use Lambda to turn your \" \n",
      "\n",
      "Number of tasks sent to review: 4\n"
     ]
    }
   ],
   "source": [
    "# Sample data, human loop started\n",
    "human_loops_started = []\n",
    "CONFIDENCE_SCORE_THRESHOLD = .3\n",
    "\n",
    "count = 0\n",
    "for index in range(1):\n",
    "    this_uri = folder_path+all_videos[index]\n",
    "    this_confidences = all_confidences[index]\n",
    "    \n",
    "    print(\"========= \" + all_videos[index] + \" =========\")\n",
    "    \n",
    "    i = 0\n",
    "    for obj in this_confidences:\n",
    "        word = obj[\"content\"]\n",
    "        neighbors, start_time, end_time = get_word_neighbors(this_confidences, i)\n",
    "\n",
    "        # Our condition for when we want to engage a human for review\n",
    "        if (obj[\"confidence\"] < CONFIDENCE_SCORE_THRESHOLD):\n",
    "\n",
    "            # get the original sequence of words\n",
    "            sequence = \"\"\n",
    "            for block in neighbors:\n",
    "                sequence += block['content'] + \" \"\n",
    "\n",
    "            humanLoopName = str(uuid.uuid4())\n",
    "            # \"initialValue\": word,\n",
    "            inputContent = {\n",
    "                \"audioPath\": this_uri,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"original_words\": sequence,\n",
    "                \"video_title\": all_videos[index]\n",
    "            }\n",
    "            start_loop_response = a2i.start_human_loop(\n",
    "                HumanLoopName=humanLoopName,\n",
    "                FlowDefinitionArn=flowDefinitionArn,\n",
    "                HumanLoopInput={\n",
    "                    \"InputContent\": json.dumps(inputContent)\n",
    "                }\n",
    "            )\n",
    "            human_loops_started.append(humanLoopName)\n",
    "            print(f'Confidence score of {obj[\"confidence\"]} is less than the threshold of {CONFIDENCE_SCORE_THRESHOLD}')\n",
    "            print(f'Starting human loop with name: {humanLoopName}')\n",
    "            print(f'Sending words from times {start_time} to {end_time} to review')\n",
    "            print(f'The original transcription is \"{sequence}\" \\n')\n",
    "            \n",
    "            count = count + 1\n",
    "        else:\n",
    "            print(f'SentimentScore of {obj[\"confidence\"]} is above threshold of {CONFIDENCE_SCORE_THRESHOLD}')\n",
    "            print('No human loop created. \\n')\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "print(f'Number of tasks sent to review: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save the name of each human loop, in case we need to retrieve them later after shutting down this notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_hl = open(\"human_loops_names.txt\",\"w\") \n",
    "for name in human_loops_started:\n",
    "    file_hl.write(name + \"\\n\") \n",
    "file_hl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 4865272f-d67e-4307-a83d-afd1a8d80101\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/4865272f-d67e-4307-a83d-afd1a8d80101/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: eac3afb2-68ef-478d-a1bd-d6e4bec513af\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/eac3afb2-68ef-478d-a1bd-d6e4bec513af/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: 1bd85798-6c78-45fd-9021-74444c0ab4af\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/1bd85798-6c78-45fd-9021-74444c0ab4af/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: 11522590-23ac-4b76-98e9-1667135beb42\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/11522590-23ac-4b76-98e9-1667135beb42/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f'HumanLoop Name: {human_loop_name}')\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait For Workers to Complete Task\n",
    "We display the link to the private worker portal here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\n",
      "https://v3t960yxw8.labeling.us-west-2.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "# Wait For Workers to Complete Task\n",
    "workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n",
    "print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n",
    "print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Status of Human Loop Again\n",
    "Wait for all human loop statuses to display `Completed` before continuing to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 4865272f-d67e-4307-a83d-afd1a8d80101\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/4865272f-d67e-4307-a83d-afd1a8d80101/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: eac3afb2-68ef-478d-a1bd-d6e4bec513af\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/eac3afb2-68ef-478d-a1bd-d6e4bec513af/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: 1bd85798-6c78-45fd-9021-74444c0ab4af\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/1bd85798-6c78-45fd-9021-74444c0ab4af/output.json'}\n",
      "\n",
      "\n",
      "HumanLoop Name: 11522590-23ac-4b76-98e9-1667135beb42\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://jashuang-sagemaker-5-22/a2i-results/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0/2020/06/18/18/42/30/11522590-23ac-4b76-98e9-1667135beb42/output.json'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f'HumanLoop Name: {human_loop_name}')\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Task Results\n",
    "\n",
    "Once work is completed, Amazon A2I stores results in your S3 bucket and sends a Cloudwatch event. Your results should be available in the S3 `OUTPUT_PATH` when all work is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'flowDefinitionArn': 'arn:aws:sagemaker:us-west-2:688520471316:flow-definition/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0',\n",
      "    'humanAnswers': [   {   'answerContent': {   'transcription': 'the '\n",
      "                                                                  'Internet so '\n",
      "                                                                  'this is '\n",
      "                                                                  'from '},\n",
      "                            'submissionTime': '2020-06-18T18:43:57.310Z',\n",
      "                            'workerId': 'ef7294f850a3d9d1',\n",
      "                            'workerMetadata': {   'identityData': {   'identityProviderType': 'Cognito',\n",
      "                                                                      'issuer': 'https://cognito-idp.us-west-2.amazonaws.com/us-west-2_rDB2Sn2uV',\n",
      "                                                                      'sub': 'c6aa8eb7-9944-42e9-a6b9-f8b270e77860'}}}],\n",
      "    'humanLoopName': '4865272f-d67e-4307-a83d-afd1a8d80101',\n",
      "    'inputContent': {   'audioPath': 's3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed '\n",
      "                                     'Notebook Instances with Amazon SageMaker '\n",
      "                                     '- a Deep Dive.mp4',\n",
      "                        'end_time': 802.63,\n",
      "                        'original_words': 'the Internet s Oh this is from ',\n",
      "                        'start_time': 800.84,\n",
      "                        'video_title': 'Fully-Managed Notebook Instances with '\n",
      "                                       'Amazon SageMaker - a Deep Dive.mp4'}}\n",
      "\n",
      "\n",
      "{   'flowDefinitionArn': 'arn:aws:sagemaker:us-west-2:688520471316:flow-definition/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0',\n",
      "    'humanAnswers': [   {   'answerContent': {   'transcription': 'this is '\n",
      "                                                                  'from Sarraf '\n",
      "                                                                  \"He's the \"\n",
      "                                                                  'author'},\n",
      "                            'submissionTime': '2020-06-18T18:44:38.995Z',\n",
      "                            'workerId': 'ef7294f850a3d9d1',\n",
      "                            'workerMetadata': {   'identityData': {   'identityProviderType': 'Cognito',\n",
      "                                                                      'issuer': 'https://cognito-idp.us-west-2.amazonaws.com/us-west-2_rDB2Sn2uV',\n",
      "                                                                      'sub': 'c6aa8eb7-9944-42e9-a6b9-f8b270e77860'}}}],\n",
      "    'humanLoopName': 'eac3afb2-68ef-478d-a1bd-d6e4bec513af',\n",
      "    'inputContent': {   'audioPath': 's3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed '\n",
      "                                     'Notebook Instances with Amazon SageMaker '\n",
      "                                     '- a Deep Dive.mp4',\n",
      "                        'end_time': 803.78,\n",
      "                        'original_words': \"this is from Sarraf He's the \"\n",
      "                                          'author ',\n",
      "                        'start_time': 802.17,\n",
      "                        'video_title': 'Fully-Managed Notebook Instances with '\n",
      "                                       'Amazon SageMaker - a Deep Dive.mp4'}}\n",
      "\n",
      "\n",
      "{   'flowDefinitionArn': 'arn:aws:sagemaker:us-west-2:688520471316:flow-definition/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0',\n",
      "    'humanAnswers': [   {   'answerContent': {   'transcription': 'right up '\n",
      "                                                                  'here then '\n",
      "                                                                  'the title '\n",
      "                                                                  'of'},\n",
      "                            'submissionTime': '2020-06-18T18:46:37.516Z',\n",
      "                            'workerId': 'ef7294f850a3d9d1',\n",
      "                            'workerMetadata': {   'identityData': {   'identityProviderType': 'Cognito',\n",
      "                                                                      'issuer': 'https://cognito-idp.us-west-2.amazonaws.com/us-west-2_rDB2Sn2uV',\n",
      "                                                                      'sub': 'c6aa8eb7-9944-42e9-a6b9-f8b270e77860'}}}],\n",
      "    'humanLoopName': '1bd85798-6c78-45fd-9021-74444c0ab4af',\n",
      "    'inputContent': {   'audioPath': 's3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed '\n",
      "                                     'Notebook Instances with Amazon SageMaker '\n",
      "                                     '- a Deep Dive.mp4',\n",
      "                        'end_time': 844.76,\n",
      "                        'original_words': 'right up here then the title of ',\n",
      "                        'start_time': 842.92,\n",
      "                        'video_title': 'Fully-Managed Notebook Instances with '\n",
      "                                       'Amazon SageMaker - a Deep Dive.mp4'}}\n",
      "\n",
      "\n",
      "{   'flowDefinitionArn': 'arn:aws:sagemaker:us-west-2:688520471316:flow-definition/demo-fd-transcribe-6199e8ef-b22b-4d68-ae60-8cb93885ead0',\n",
      "    'humanAnswers': [   {   'answerContent': {   'transcription': 'but '\n",
      "                                                                  'definitely '\n",
      "                                                                  'use Lambda '\n",
      "                                                                  'to turn '\n",
      "                                                                  'your'},\n",
      "                            'submissionTime': '2020-06-18T18:43:41.290Z',\n",
      "                            'workerId': 'ef7294f850a3d9d1',\n",
      "                            'workerMetadata': {   'identityData': {   'identityProviderType': 'Cognito',\n",
      "                                                                      'issuer': 'https://cognito-idp.us-west-2.amazonaws.com/us-west-2_rDB2Sn2uV',\n",
      "                                                                      'sub': 'c6aa8eb7-9944-42e9-a6b9-f8b270e77860'}}}],\n",
      "    'humanLoopName': '11522590-23ac-4b76-98e9-1667135beb42',\n",
      "    'inputContent': {   'audioPath': 's3://jashuang-sagemaker-5-22/a2i_transcribe_demo/Fully-Managed '\n",
      "                                     'Notebook Instances with Amazon SageMaker '\n",
      "                                     '- a Deep Dive.mp4',\n",
      "                        'end_time': 950.27,\n",
      "                        'original_words': 'but definitely use Lambda to turn '\n",
      "                                          'your ',\n",
      "                        'start_time': 948.51,\n",
      "                        'video_title': 'Fully-Managed Notebook Instances with '\n",
      "                                       'Amazon SageMaker - a Deep Dive.mp4'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    pp.pprint(json_output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Custom vocabularies using A2I results\n",
    "\n",
    "Using the corrected transcriptions from our human reviewers, let’s parse through these results to identify the domain-specific terms that we want to add to a custom vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve A2I results\n",
    "To get the technical terms identified by human review, we first accumulate all human-reviewed words into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "corrected_words = []\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    splitted_string = re.split('s3://' +  BUCKET + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n",
    "    output_bucket_key = splitted_string[1]\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=output_bucket_key)\n",
    "    content = response[\"Body\"].read()\n",
    "    json_output = json.loads(content)\n",
    "    \n",
    "    # add the human-reviewed answers split by spaces\n",
    "    corrected_words += [word.strip(punctuation).lower() for word in json_output['humanAnswers'][0]['answerContent']['transcription'].split(\" \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out common English words\n",
    "Now, we want to parse through these words and look for “uncommon” English words. An easy way to do this is to use a large English corpus and verify whether each of our human-reviewed words exists in this corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of English words\n",
    "# Note that this corpus of words is not 100% exhaustive\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "my_dict=set(words.words()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing contractions\n",
    "# Source: https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "def remove_contractions(word_list):\n",
    "    return [word for word in word_list if word not in contractions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Technical/Uncommon Words\n",
    "After removing contractions, human-reviewed words that are not in the English language corpus are likely to be the technical terms we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set([])\n",
    "for word in remove_contractions(corrected_words):\n",
    "    if word:\n",
    "        if word.lower() not in my_dict:\n",
    "            if word.endswith('s') and word[:-1] in my_dict:\n",
    "                print(\"\")\n",
    "            elif word.endswith(\"'s\") and word[:-2] in my_dict:\n",
    "                print(\"\")\n",
    "            else:\n",
    "                word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internet\n"
     ]
    }
   ],
   "source": [
    "for word in word_set:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Vocabulary\n",
    "Using the technical terms identified above, it is now easier to manually create a custom vocabulary of those terms that we want Transcribe to be able to recognize. A custom vocabulary table enables options to tell Amazon Transcribe how each technical term is pronounced and how it should be displayed. More details on how to form a custom vocabulary table can be found [here](https://docs.aws.amazon.com/transcribe/latest/dg/how-vocabulary.html#create-vocabulary-table)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as you process additional videos on the same topic, you can keep updating this list, and the number of new technical terms you'll have to add will likely decrease each time you get a new video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built in advance a custom vocabulary (below) using parsed A2I results from the first and third videos with a 0.5 `THRESHOLD` confidence value. You can use this vocabulary for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_words=[['Phrase','IPA','SoundsLike','DisplayAs'], # This top line denote the column headers of the text file.\n",
    "                 ['machine-learning','','','machine learning'],\n",
    "                 ['amazon','','am-uh-zon','Amazon'],\n",
    "                 ['boto-three','','boe-toe-three','Boto3'],\n",
    "                 ['T.-three','','tee-three','T3'],\n",
    "                 ['Sarab','','suh-rob','Sarab'],\n",
    "                 ['E.C.R.','','ee-see-are','ECR'],\n",
    "                 ['E.B.S.','','ee-bee-ess','EBS'],\n",
    "                 ['jupyter','','joo-pih-ter','Jupyter'],\n",
    "                 ['opt-M.L.','','opt-em-ell','/opt/ml'],\n",
    "                 ['desktop','','desk-top','desktop'],\n",
    "                 ['S.-Three','','ess-three','S3'],\n",
    "                 ['S.D.K.','','ess-dee-kay','SDK'],\n",
    "                 ['sagemaker','','sage-may-ker','SageMaker'],\n",
    "                 ['mars-dot-r','','mars-dot-are','mars.R'],\n",
    "                 ['I.A.M.','','eye-ay-em','IAM'],\n",
    "                 ['V.P.C.','','','VPC'],\n",
    "                 ['E.C.-Two','','ee-see-too','EC2'],\n",
    "                 ['blazing-text','','','BlazingText'],\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Custom Vocabulary Table to a Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vocab_file_name = \"customvocab4.txt\"\n",
    "file1 = open(custom_vocab_file_name,\"w\")\n",
    "template = '{}\\t{}\\t{}\\t{}\\n'\n",
    "for line in finalized_words:\n",
    "    file1.write(template.format(line[0],\n",
    "                                line[1],\n",
    "                                line[2],\n",
    "                                line[3])\n",
    "               )\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Custom Vocabulary File to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(custom_vocab_file_name, BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Custom Vocabulary\n",
    "After saving your custom vocabulary table to a text file and uploading it to an S3 bucket, create your custom vocabulary with a specified name so that Amazon Transcribe can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_improved='sagemaker-custom-vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client(\"transcribe\")\n",
    "response = transcribe.create_vocabulary(\n",
    "    VocabularyName=vocab_improved,\n",
    "    LanguageCode='en-US',\n",
    "    VocabularyFileUri='s3://' + BUCKET + '/' + custom_vocab_file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'LanguageCode': 'en-US',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'connection': 'keep-alive',\n",
      "                                               'content-length': '94',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Thu, 18 Jun 2020 '\n",
      "                                                       '17:10:27 GMT',\n",
      "                                               'x-amzn-requestid': 'd12b1f5d-6364-49db-8f04-758fb1cf8435'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'd12b1f5d-6364-49db-8f04-758fb1cf8435',\n",
      "                            'RetryAttempts': 0},\n",
      "    'VocabularyName': 'sagemaker-custom-vocab',\n",
      "    'VocabularyState': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'DownloadUri': 'https://s3.us-west-2.amazonaws.com/aws-transcribe-dictionary-model-us-west-2-prod/688520471316/sagemaker-custom-vocab/158367ef-4f1b-4638-b105-2093a5a6d8d9/input.txt?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHgaCXVzLXdlc3QtMiJHMEUCIEQxxGfsgrxPom7GSV2xIJ5ptj8In0sA%2Bl6KkwUug3tiAiEAgTWECYaTUI2QWTB5kuwm%2B6lI2MlfMhXWF3b3X1DU6poqvQMI8f%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgwwODAyNDgzMjIyMDYiDPgMoY%2Fdki1qD6jheiqRAxrbXsRpIle5808yXU7%2BOZoh9gdRwNaJ0qQGJMJrrMTq9mKGJiQXJ3rL1B6WXSzNh8uZTfjoCx7pOVUoFO2HV9vURdjgXtdy3WY9XPyol8%2FZHRRHX3Lqy3Rs%2F1oOXDkpkCWJ%2FO%2BkkDJiCq8y%2F6uKqqvfNEBNH6HEyDcycwN0e3uNEn1Z3AXOsJbSyHcrIwB7tmuDaMMt0JDtLpzCO70dRMfyZDoQhLPn1y4FjUTQATIw9CmsOh6kN4Leo2o0zq0aEWeQdsYx5vCVo313GQEXSNCX6GWUgigB%2FVrr9FKYEhpf3WttdVg7kPaS74Jb72uxQV8cMXlJpFSgH11eP9VyuPCOqGlJGEiW6HCHL6Oe5doGvSX1eC%2B4miY8bT%2FUqk2byB9G9mxjKrqO%2BlgsbzJPIAXuLyl3Kq84YGCAjSd1WyKCUAtW3Nj9qtRG5PnW9CPjuFnDqDglV%2BO20nXt%2Bymz1sZVYgo4RfTfWPauuuxuI4BvnjbbxzhmPZ%2Bl3X7sCelIuiqYgZMYaoorlZuwBPCOJZIfMM2crvcFOusBVvIK3o9aXKH5iJ%2FHtq86bYaGbJq0UeJqt7T0f7Uv9pBsPk6QVccVAGyFnWysf2ljwTvNsVnGWchaU%2FIpffTCRL5oq%2BwYzrXX20u4EYAge3ZNmBV0DwrziWZufi4g3x7dT86pdfgHouoAQ%2BJ13eySIOKyYnuqUJj77CoQQATJIkfTAaeLT77088VkwGEfNrdBvsxZPm5lAIlPnXnVCLoYLlCInwXg%2Fx7eCB4CbV8xXWfAwCAbmePIoCEREedkBICJjguuCi3u4NxyAHT4ONJfEcyFjssCokR5MKW2%2B4GlkZpeoi7IsQNFyvmeAA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200618T171203Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIARFLZMHCPMU5ULH6O%2F20200618%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=8e32c4ba0f8adb8c219720ff2b02f96d168e04f7ca3919893a4b712ef443ede1',\n",
      "    'LanguageCode': 'en-US',\n",
      "    'LastModifiedTime': datetime.datetime(2020, 6, 18, 17, 10, 28, 430000, tzinfo=tzlocal()),\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'connection': 'keep-alive',\n",
      "                                               'content-length': '1720',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Thu, 18 Jun 2020 '\n",
      "                                                       '17:12:03 GMT',\n",
      "                                               'x-amzn-requestid': 'a90d3e34-8043-483f-8c10-0105dab5c6df'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'a90d3e34-8043-483f-8c10-0105dab5c6df',\n",
      "                            'RetryAttempts': 0},\n",
      "    'VocabularyName': 'sagemaker-custom-vocab',\n",
      "    'VocabularyState': 'READY'}\n"
     ]
    }
   ],
   "source": [
    "# Get the status of the vocab you created again (must wait until its VocabularyState is READY)\n",
    "response2 = transcribe.get_vocabulary(\n",
    "    VocabularyName=vocab_improved\n",
    ")\n",
    "pp.pprint(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improved Transcription using your Custom Vocabulary\n",
    "\n",
    "### Re-transcribe using the Custom Vocabulary\n",
    "Let's re-transcribe video using our custom vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New job names\n",
    "# In-sample videos\n",
    "job_name_custom_vid_0='AWS-custom-0-using-' + vocab_improved + str(time_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names_custom = [job_name_custom_vid_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------mp4\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'AWS-custom-0-using-sagemaker-custom-vocab16.54.21', 'TranscriptionJobStatus': 'IN_PROGRESS', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp4', 'Media': {'MediaFileUri': 's3://chopt-a2i-test-sagemaker/a2i_transcribe_demo/Fully-Managed Notebook Instances with Amazon SageMaker - a Deep Dive.mp4'}, 'Transcript': {}, 'StartTime': datetime.datetime(2020, 6, 18, 17, 17, 52, 213000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 6, 18, 17, 17, 52, 189000, tzinfo=tzlocal()), 'Settings': {'VocabularyName': 'sagemaker-custom-vocab', 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': 'a16040bc-3e44-44dd-bd52-c88b9b2590da', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Thu, 18 Jun 2020 17:17:54 GMT', 'x-amzn-requestid': 'a16040bc-3e44-44dd-bd52-c88b9b2590da', 'content-length': '545', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Start another transcription job using your custom vocabulary.\n",
    "transcribe(job_name_custom_vid_0, folder_path+all_videos[0], BUCKET, vocab_name=vocab_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of your transcription job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(transcribe_client.get_transcription_job(TranscriptionJobName=job_name_custom_vid_0)['TranscriptionJob']['TranscriptionJobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchKey",
     "evalue": "An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-13a15fb17610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_scores_custom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mentire_transcript_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_and_times_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transcript_text_and_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUCKET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjob_names_custom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mall_entire_transcript_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentire_transcript_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mall_sentences_and_times_custom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_and_times_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-269-0240a267eb03>\u001b[0m in \u001b[0;36mget_transcript_text_and_timestamps\u001b[0;34m(bucket_name, file_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ms3_clientobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0ms3_clientdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_clientobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Body\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist."
     ]
    }
   ],
   "source": [
    "all_entire_transcript_custom = []\n",
    "all_sentences_and_times_custom = []\n",
    "all_confidences_custom = []\n",
    "all_scores_custom = []\n",
    "for i in range(1):\n",
    "    entire_transcript_1, sentences_and_times_1, confidences_1, scores_1 = get_transcript_text_and_timestamps(BUCKET,job_names_custom[i]+\".json\")\n",
    "    all_entire_transcript_custom.append(entire_transcript_1)\n",
    "    all_sentences_and_times_custom.append(sentences_and_times_1)\n",
    "    all_confidences_custom.append(confidences_1)\n",
    "    all_scores_custom.append(scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-017d7063f6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sentences_and_times_custom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Sanity check!\n",
    "print(all_sentences_and_times_custom[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Improved Transcripts to Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the improved transcripts\n",
    "i = 1\n",
    "for list_ in all_sentences_and_times_custom:   \n",
    "    file = open(f\"improved_transcript_{i}.txt\",\"w\")\n",
    "    for tup in list_:\n",
    "        file.write(tup['sentence'] + \"\\n\") \n",
    "    file.close()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze metrics on a larger sample size for this workflow, we've generated in advance a ground truth transcript, a transcription before custom vocabulary, and a transcription after custom vocabulary for each of the first four videos of the playlist. The first and third videos are the in-sample videos used to build the custom vocabulary you saw earlier. The second and fourth videos are used as out-sample videos to test Transcribe again after building the custom vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to import the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf a2i_transcribe_demo_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/improved_transcript_2.txt to a2i_transcribe_demo_results/improved_transcript_2.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/ground_truth_1.txt to a2i_transcribe_demo_results/ground_truth_1.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/customvocab4.txt to a2i_transcribe_demo_results/customvocab4.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/original_transcript_3.txt to a2i_transcribe_demo_results/original_transcript_3.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/improved_transcript_1.txt to a2i_transcribe_demo_results/improved_transcript_1.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/ground_truth_3.txt to a2i_transcribe_demo_results/ground_truth_3.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/original_transcript_2.txt to a2i_transcribe_demo_results/original_transcript_2.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/improved_transcript_4.txt to a2i_transcribe_demo_results/improved_transcript_4.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/improved_transcript_3.txt to a2i_transcribe_demo_results/improved_transcript_3.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/original_transcript_1.txt to a2i_transcribe_demo_results/original_transcript_1.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/ground_truth_2.txt to a2i_transcribe_demo_results/ground_truth_2.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/ground_truth_4.txt to a2i_transcribe_demo_results/ground_truth_4.txt\n",
      "download: s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files/original_transcript_4.txt to a2i_transcribe_demo_results/original_transcript_4.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$BUCKET\"\n",
    "mkdir a2i_transcribe_demo_results\n",
    "aws s3 sync s3://aws-ml-blog/artifacts/a2i-transcribe-custom-demo/demo-txt-files ./a2i_transcribe_demo_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculating Word Error Rate (WER)\n",
    "\n",
    "The most common metric for speech recognition accuracy is called word error rate (WER), which can be roughly defined to be the proportion of transcription errors relative to the number of words that were actually said. More details can be found here (https://en.wikipedia.org/wiki/Word_error_rate).\n",
    "\n",
    "We'll be using a lightweight open-source Python library called JiWER for calculating WER between transcripts.\n",
    "\n",
    "For more details, see the open-source [description](https://pypi.org/project/jiwer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jiwer) (1.14.3)\n",
      "Requirement already satisfied: python-Levenshtein in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jiwer) (0.12.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-Levenshtein->jiwer) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small example\n",
    "ground_truth = \"hello world\"\n",
    "hypothesis = \"hello duck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer(ground_truth, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformation function to preprocess transcript\n",
    "transformation = jiwer.Compose([\n",
    "    jiwer.ToLowerCase(),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.RemoveWhiteSpace(replace_by_space=True),\n",
    "    jiwer.SentencesToListOfWords(),\n",
    "    jiwer.SentencesToListOfWords(word_delimiter=\" \"),\n",
    "    jiwer.RemoveEmptyStrings()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-sample video metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== In-sample videos =====\n",
      "Processing video #1\n",
      "The baseline WER (before using custom vocabularies) is 0.05184.\n",
      "The WER (after using custom vocabularies) is 0.02624.\n",
      "Processing video #3\n",
      "The baseline WER (before using custom vocabularies) is 0.11940298507462686.\n",
      "The WER (after using custom vocabularies) is 0.07835820895522388.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== In-sample videos =====\")\n",
    "for index in [1,3]:\n",
    "    print(f\"Processing video #{index}\")\n",
    "    # Original transcript\n",
    "    hypothesis_original = \"\"\n",
    "    f1 = open(f\"./a2i_transcribe_demo_results/original_transcript_{index}.txt\", \"r\")\n",
    "    for line in f1:\n",
    "        hypothesis_original += (line.strip() + \" \")\n",
    "    f1.close()\n",
    "    \n",
    "    # Transcript after custom vocabulary\n",
    "    hypothesis_2 = \"\"\n",
    "    f2 = open(f\"./a2i_transcribe_demo_results/improved_transcript_{index}.txt\", \"r\")\n",
    "    for line in f2:\n",
    "        hypothesis_2 += (line.strip() + \" \")\n",
    "    f2.close()\n",
    "    \n",
    "    # Ground truth transcript\n",
    "    ground_truth = \"\"\n",
    "    f3 = open(f\"./a2i_transcribe_demo_results/ground_truth_{index}.txt\", \"r\")\n",
    "    for line in f3:\n",
    "        ground_truth += (line.strip() + \" \")\n",
    "    f3.close()\n",
    "    \n",
    "    # Calculate baseline accuracy\n",
    "    baseline_accuracy = jiwer.wer(\n",
    "        ground_truth, \n",
    "        hypothesis_original, \n",
    "        truth_transform=transformation, \n",
    "        hypothesis_transform=transformation\n",
    "    )\n",
    "    \n",
    "    print(f\"The baseline WER (before using custom vocabularies) is {baseline_accuracy}.\")\n",
    "    \n",
    "    # Calculate new accuracy after custom vocabulary\n",
    "    new_accuracy = jiwer.wer(\n",
    "        ground_truth,\n",
    "        hypothesis_2, \n",
    "        truth_transform=transformation, \n",
    "        hypothesis_transform=transformation\n",
    "    )\n",
    "    \n",
    "    print(f\"The WER (after using custom vocabularies) is {new_accuracy}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-sample video metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Out-sample videos =====\n",
      "Processing video #2\n",
      "The baseline WER (before using custom vocabularies) is 0.07547814207650273.\n",
      "The new WER (after using custom vocabularies) is 0.06557377049180328.\n",
      "Processing video #4\n",
      "The baseline WER (before using custom vocabularies) is 0.10906969962088073.\n",
      "The new WER (after using custom vocabularies) is 0.08982210557013706.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Out-sample videos =====\")\n",
    "for index in [2,4]:\n",
    "    print(f\"Processing video #{index}\")\n",
    "    # Original transcript\n",
    "    hypothesis_original = \"\"\n",
    "    f1 = open(f\"./a2i_transcribe_demo_results/original_transcript_{index}.txt\", \"r\")\n",
    "    for line in f1:\n",
    "        hypothesis_original += (line.strip() + \" \")\n",
    "    f1.close()\n",
    "    \n",
    "    # Transcript after custom vocabulary\n",
    "    hypothesis_2 = \"\"\n",
    "    f2 = open(f\"./a2i_transcribe_demo_results/improved_transcript_{index}.txt\", \"r\")\n",
    "    for line in f2:\n",
    "        hypothesis_2 += (line.strip() + \" \")\n",
    "    f2.close()\n",
    "    \n",
    "    ground_truth = \"\"\n",
    "    f3 = open(f\"./a2i_transcribe_demo_results/ground_truth_{index}.txt\", \"r\")\n",
    "    for line in f3:\n",
    "        ground_truth += (line.strip() + \" \")\n",
    "    f3.close()\n",
    "    \n",
    "    # Calculate baseline accuracy\n",
    "    baseline_accuracy = jiwer.wer(\n",
    "        ground_truth, \n",
    "        hypothesis_original, \n",
    "        truth_transform=transformation, \n",
    "        hypothesis_transform=transformation\n",
    "    )\n",
    "    \n",
    "    print(f\"The baseline WER (before using custom vocabularies) is {baseline_accuracy}.\")\n",
    "    \n",
    "    # Calculate new accuracy after custom vocabulary\n",
    "    new_accuracy = jiwer.wer(\n",
    "        ground_truth,\n",
    "        hypothesis_2, \n",
    "        truth_transform=transformation, \n",
    "        hypothesis_transform=transformation\n",
    "    )\n",
    "    \n",
    "    print(f\"The new WER (after using custom vocabularies) is {new_accuracy}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We've provided a table summarizing the changes in WER scores below.\n",
    "\n",
    "|            | Video | Baseline WER (before custom vocabulary) | New WER (after custom vocabulary) | Percentage Change |\n",
    "|------------|-------|-----------------------------------------|------------------------------------|-------------------|\n",
    "| In-sample  | #1     | 5.18%                                   | 2.62%                              | -49%              |\n",
    "| In-sample  | #3     | 11.94%                                  | 7.84%                              | -34%              |\n",
    "| Out-sample | #2     | 7.55%                                   | 6.56%                              | -13%              |\n",
    "| Out-sample | #4     | 10.91%                                  | 8.98%                              | -18%              |\n",
    "\n",
    "There are several ways to interpret these results.\n",
    "\n",
    "Let's first consider the percentage change column. By definition, we have $WER=\\frac{S+D+I}{N}$, where $S$, $D$, and $I$ are the number of substitution, deletion, and insertion operations, respectively, needed to get from the outputted transcript to the ground truth, and $N$ is the total number of words. The percentage change is then the percentage change in the number of operations needed, so the decreases that we observed look pretty good.\n",
    "\n",
    "If we consider absolute WER scores, the initial WER of 5.18%, for instance, might already feel sufficiently low — that's only around 1 in 20 words that are mis-transcribed! However, this rate can be misleading, since domain-specific terms are often the least common words spoken (relative to frequent words like “to,” “and,” “I” etc.) but the most commonly mis-transcribed. For applications like search engine optimization (SEO) and video organization by topic, it could be critical that these technical terms are transcribed correctly. Let’s take a look at how our custom vocabulary impacted the transcription rates of several important technical terms:\n",
    "\n",
    "### Metrics for specific technical terms\n",
    "\n",
    "#### In-sample videos:\n",
    "\n",
    "Video #1:\n",
    "\n",
    "| Technical Term | Ground Truth mentions | Original Transcript Mentions | New Transcript Mentions | Percentage Point Change |\n",
    "|----------------|-----------------------|------------------------------|-------------------------|-------------------------|\n",
    "| SageMaker      | 22                    | 4 (18%)                      | 22 (100%)               | +82%                    |\n",
    "| EC2            | 15                    | 1 (7%)                       | 15 (100%)               | +93%                    |\n",
    "| EBS            | 11                    | 7 (64%)                      | 11 (100%)                | +36%                    |\n",
    "| Jupyter        | 5                     | 0 (0%)                       | 5 (100%)                | +100%                   |\n",
    "| S3             | 3                     | 0 (0%)                       | 3 (100%)                | +100%                   |\n",
    "| SDK            | 2                     | 0 (0%)                        | 2 (100%)                | +100%                 |\n",
    "| BlazingText    | 2                     | 0 (0%)                        | 2 (100%)                | +100%                 |\n",
    "| IAM            | 1                     | 0 (0%)                        | 1 (100%)                | +100%                 |\n",
    "| **Total**      | **61**               | **12 (20%)**                  | **61 (100%)**           | **+80%**               |\n",
    "\n",
    "Video #3:\n",
    "\n",
    "| Technical Term | Ground Truth mentions | Original Transcript Mentions | New Transcript Mentions | Percentage Point Change |\n",
    "|----------------|-----------------------|------------------------------|-------------------------|-------------------------|\n",
    "| SageMaker      | 17                    | 4 (24%)                      | 17 (100%)               | +76%                    |\n",
    "| ECR            | 7                     | 0 (0%)                       | 7 (100%)                | +100%                    |\n",
    "| /opt/ml        | 6                     | 0 (0%)                       | 6 (100%)                | +100%                    |\n",
    "| mars.R         | 3                     | 0 (0%)                       | 3 (100%)                | +100%                   |\n",
    "| S3             | 1                     | 0 (0%)                       | 1 (100%)                | +100%                   |\n",
    "| **Total**      | **34**               | **4 (12%)**                  | **34 (100%)**           | **+88%**               |\n",
    "\n",
    "\n",
    "#### Out-sample videos:\n",
    "\n",
    "Video #2:\n",
    "\n",
    "| Technical Term | Ground Truth mentions | Original Transcript mentions | New Transcript mentions | Percentage Point Change |\n",
    "|----------------|-----------------------|------------------------------|-------------------------|-------------------------|\n",
    "| SageMaker      | 12                    | 3 (25%)                      | 12 (100%)               | +75%                    |\n",
    "| BlazingText    | 3                     | 0 (0%)                       | 3 (100%)                | +100%                   |\n",
    "| ECR            | 1                     | 0 (0%)                       | 1 (100%)                | +100%                   |\n",
    "| **Total**      | **16**               | **3 (19%)**                  | **16 (100%)**           | **+81%**               |\n",
    "\n",
    "Video #4:\n",
    "\n",
    "| Technical Term | Ground Truth mentions | Original Transcript mentions | New Transcript mentions | Percentage Point Change |\n",
    "|----------------|-----------------------|------------------------------|-------------------------|-------------------------|\n",
    "| SageMaker      | 21                    | 4 (19%)                      | 20 (95%)                | +75%                    |\n",
    "| EC2            | 11                    | 0 (0%)                       | 11 (100%)               | +100%                    |\n",
    "| S3             | 7                     | 0 (0%)                       | 6 (86%)                 | +86%                    |\n",
    "| ECR            | 2                     | 0 (0%)                       | 2 (100%)                | +100%                   |\n",
    "| SDK            | 1                     | 0 (0%)                       | 1 (100%)                | +100%                   |\n",
    "| EBS            | 1                     | 1 (100%)                     | 1 (100%)                | +0%                     |\n",
    "| **Total**      | **43**               | **3 (12%)**                  | **41 (95%)**           | **+83%**               |\n",
    "\n",
    "\n",
    "Now it does look like custom vocabularies were certainly worth the effort!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up\n",
    "To avoid incurring unnecessary charges, delete resources when not in use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In this post, we walked through an example of how you can improve transcripts from Amazon Transcribe using custom vocabularies and an Amazon A2I human review workflow. This allows you to quickly identify domain-specific terms using your own private workforce and review workflows, and use these terms to build a custom vocabulary so that future mentions of term are transcribed with greater accuracy, at scale. Transcribing key technical terms correctly can be important for doing SEO, enabling highly specific textual queries, and grouping large quantities of video or audio files by important technical terms.\n",
    "\n",
    "The full proof-of-concept Jupyter notebook can be found at this Github repository. Check out other blog posts covering integrations of Amazon A2I, such as [Using Amazon Textract with Amazon Augmented AI for processing critical documents](https://aws.amazon.com/blogs/machine-learning/using-amazon-textract-with-amazon-augmented-ai-for-processing-critical-documents/) and [Designing human review workflows with Amazon Translate and Amazon Augmented AI](https://aws.amazon.com/blogs/machine-learning/designing-human-review-workflows-with-amazon-translate-and-amazon-augmented-ai/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End!\n",
    "For a more detailed discussion with additional visuals, check out the accompanying blog post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
