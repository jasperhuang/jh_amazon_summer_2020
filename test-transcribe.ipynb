{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::688520471316:role/service-role/AmazonSageMaker-ExecutionRole-20200522T134110'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "REGION = 'us-west-2'\n",
    "\n",
    "ROLE = get_execution_role()\n",
    "display(ROLE)\n",
    "# need to attach policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ComprehendFullAccess \n",
    "## AmazonSageMakerFullAccess \n",
    "## AmazonS3FullAccess \n",
    "## AmazonAugmentedAIFullAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client('transcribe', REGION)\n",
    "s3 = boto3.client(\"s3\", REGION)\n",
    "job_name_1 = \"AWS-sage-1\"\n",
    "job_uri_1 = \"https://jashuang-sagemaker-5-22.s3-us-west-2.amazonaws.com/transcribe-bucket/Fully-Managed+Notebook+Instances+with+Amazon+SageMaker+-+a+Deep+Dive.mp4\"\n",
    "out_bucket = \"jashuang-sagemaker-5-22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(job_name, job_uri, out_bucket, format=\"mp4\"):\n",
    "    \"\"\"Transcribe a .wav or .mp4 file to text.\n",
    "    Args:\n",
    "        job_name (str): the name of the job that you specify;\n",
    "                        the output json will be job_name.json\n",
    "        job_uri (str): input path (in s3) to the file being transcribed\n",
    "        out_bucket (str): s3 bucket name that you want the output json\n",
    "                          to be placed in\n",
    "        format (str): mp4 or wav for input file format;\n",
    "                      defaults to mp4\n",
    "    \"\"\"\n",
    "    \n",
    "    if format not in ['mp3','mp4','wav','flac']:\n",
    "        print(\"Invalid format\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        transcribe = boto3.client(\"transcribe\")\n",
    "        print(\"------\" + format)\n",
    "        transcribe.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={\"MediaFileUri\": job_uri},\n",
    "            MediaFormat=format,\n",
    "            LanguageCode=\"en-US\",\n",
    "            OutputBucketName=out_bucket,\n",
    "        )\n",
    "        \n",
    "        while True:\n",
    "            status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "            if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "                break\n",
    "            print(\"Not ready yet...\")\n",
    "            time.sleep(5)\n",
    "        print(status)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_text_and_timestamps(bucket_name, file_name):\n",
    "    \"\"\"take json file from s3 bucket and returns a tuple of:\n",
    "       entire transcript, list object of tuples of timestamp and individual sentences\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): name of s3 bucket\n",
    "        file_name (str): name of file\n",
    "    Returns:\n",
    "        (entire_transcript: str,\n",
    "        [ {timestamp (in seconds) : int, sentence : str} ])\n",
    "    \"\"\"\n",
    "    s3_clientobj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "    s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    original = json.loads(s3_clientdata)\n",
    "    items = original[\"results\"][\"items\"]\n",
    "    entire_transcript = original[\"results\"][\"transcripts\"]\n",
    "\n",
    "    sentences_and_times = []\n",
    "    temp_sentence = \"\"\n",
    "    temp_start_time = 0\n",
    "    newSentence = True\n",
    "    \n",
    "    confidences = []\n",
    "\n",
    "    for item in items:\n",
    "        # always add the word\n",
    "        if item[\"type\"] == \"punctuation\":\n",
    "            temp_sentence = (\n",
    "                temp_sentence.strip() + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "            )\n",
    "        else:\n",
    "            temp_sentence = temp_sentence + item[\"alternatives\"][0][\"content\"] + \" \"\n",
    "\n",
    "        # if this is a new sentence, and it starts with a word, save the time\n",
    "        if newSentence == True:\n",
    "            if item[\"type\"] == \"pronunciation\":\n",
    "                temp_start_time = float(item[\"start_time\"])\n",
    "            newSentence = False\n",
    "        # else, keep going until you hit a punctuation\n",
    "        else:\n",
    "            if (\n",
    "                item[\"type\"] == \"punctuation\"\n",
    "                and item[\"alternatives\"][0][\"content\"] != \",\"\n",
    "            ):\n",
    "                sentences_and_times.append(\n",
    "                    {\"time\": temp_start_time, \"sentence\": temp_sentence.strip()}\n",
    "                )\n",
    "                # reset the temp sentence\n",
    "                newSentence = True\n",
    "                temp_sentence = \"\"\n",
    "\n",
    "    return entire_transcript, sentences_and_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------mp4\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'AWS-sage-1', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp4', 'Media': {'MediaFileUri': 'https://jashuang-sagemaker-5-22.s3-us-west-2.amazonaws.com/transcribe-bucket/Fully-Managed+Notebook+Instances+with+Amazon+SageMaker+-+a+Deep+Dive.mp4'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-west-2.amazonaws.com/jashuang-sagemaker-5-22/AWS-sage-1.json'}, 'StartTime': datetime.datetime(2020, 5, 22, 23, 18, 6, 461000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 5, 22, 23, 18, 6, 432000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 5, 22, 23, 20, 32, 205000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '5d6f2aa1-ec81-44cd-9273-ee0d8e2ac7f8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Fri, 22 May 2020 23:20:32 GMT', 'x-amzn-requestid': '5d6f2aa1-ec81-44cd-9273-ee0d8e2ac7f8', 'content-length': '619', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "transcribe(job_name_1, job_uri_1, out_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_transcript_1, sentences_and_times_1 = get_transcript_text_and_timestamps(\"jashuang-sagemaker-5-22\",\"AWS-sage-1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'transcript': \"Hi. My name is Emily Weber. I'm a machine learning specialist at Amazon Web services on today. We're gonna talk about insolence. Age maker Comes on Stage Maker is a fully managed machine learning service that developers and data scientists can use to build, train and deploy machine learning models. Today, we're gonna talk about notebook instances and this is ready. Dive. So with the notebook instances on stage maker, it all starts with a notebook, right? And within the notebook, it starts with your easy to instance. You're easy to instance that's your elastic compute cloud. That's your virtual machine that's going to spin up and let us do all of our processing. This is a managed, easy to instance. That means that even though we're turning it on and off, it's not gonna show up. Under are easy to console, and we're not gonna have ssh access to this machine. It's gonna be fully managed by Amazon. We want to pick the right family. You're easy to instances gonna come in many different shapes and sizes. And there are families of easy to instance. T is the tiny that's the smallest, most frugal, most humble option, and the is slightly larger. That's gonna have more memory. And more cores, see is compute optimized and P stands for GPU. After that, you're gonna want to pick the right size, and this is gonna range anywhere from medium to very, very large. You can have a lot of flexibility with selecting the right size on your easy to instance. Also, you want to pick the right version. So every version of Annecy two instance is of the latest version that's been produced by the team. So that three that's highlighted that stands for the most recent version in the T family. The large number of means that it came out more recently and the latest version of an easy two instances always gonna be more cost optimal. After that, we're gonna want to add an E. B s volume. And so again, Sage maker is a managed service. So the CBS volume is also not going to show up under EBS views. However, sage maker is gonna be putting these two things together for us. Any BS has a really special property. That property is that it's gonna be able to store data for us. So we want to get the size right. By default, you're gonna get five gigabytes. However, if you're working on a machine learning project that has more than five gigs which many, many machine learning products do have more than five gigs, we're gonna want to pick the right EBS volume for you. And typically, I do slightly more than the amount of data that I actually need. I'm not trying to have a large volume and then be charged for it. But you want a little bit of breathing room, So So pick something that's slightly larger than what do you actually need? And then on top of that, remember that everything on that EBS volume is gonna persist. So, you know, even if we turn our easy to instance on and off for simple when we go home at the end of the day, in order to keep our costs down, we still want to hold on to that data set, and we want to hold onto our code. And both of those are gonna live on TBS. We also want to add or create a git repository. And so those repositories are gonna give us access to Oliver code. It's how we're gonna share our code with other developers and data scientists. And with in sagemaker, you can add get repositories that are automatically installed onto notebook instance, one that's created after that. A few more settings. So we have security settings. This is gonna include topics like encryption. If we're working with extremely sensitive data, we want to make sure that it's encrypted properly, including root volume access to our instant. So if we need to shut that down under secure settings, we certainly can. Internet access is another component. If we want to disable Internet access, we've full capacity to do that. In addition to connecting our notebook instance to our vpc so that it's locked down within that virtual firewall. Also, we have the option of using a lifecycle configuration. Your life cycle conflict is a bash script that's gonna run every time you start or create a notebook instance, and it's just a bash shell so you can get cloned. You can pip install. You can copy data from S three that is gonna have a time out of run around 15 minutes. And so if you are installing a package that takes longer of them that time out. Go ahead and drop in an ampersand in the lines so that it actually runs in background of your notebook. Instance. After that, if you want to run a machinery model on that no book instance, we're going to cover all of the five ways that you can train models in stage Maker locally is just one of them, but you certainly can. You can attach a portion of a GPU to that easy to instance, and that is a new instance size that came out a new instance. Siri's that's called elastic inference. And this elastic inference is a portion of a GPU that you can attach directly to your easy to instance in order to run inference locally, and you're gonna want us to let that based on your size version and bandwidth after that. So you got your notebook instance created, and then you'll click the button that says, Open Jupiter, and that's going to take you to this page. If you're new to Jupiter, we're gonna walk you through some of the features here. So first off, that is all of your data. All the folders, all the files, all the content that you want actually process is sitting right there in that list. For men that forth have been from the right those Air 200 example notebooks that are managed by the stage maker team section. Those are actually coming out directly from us in order to show our customers features that they need to know about. So if they're interested in understanding how stage Maker's gonna handle training machine learning models using our or using care, OSCE or PYTORCH or any other capabilities in addition to distributing data sets wanted by putt mode, all of those examples are in that folder. Also over on the right hand side, there's a new button. You can select the new button and then cruise down to create new notebooks and terminals. We're gonna learn about the terminal feature right here. So on the right hand side, you select new and then down on the left hand side, you're gonna select create a new terminal, and then this is gonna open up your view. And so the terminal that is something that exists within every Jupiter environment that folks are gonna use. However, many of us weren't necessarily aware of it prior to using sage maker because the most common polices to develop Jupiter's based solutions are either on a desktop or there on a server. And if they're on a desktop, we typically already have a bash shell that's already opened up. So we wouldn't even need to see it within that desktop view. And if it's on a server than typically will have a putty or some type of other ssh connection that's actually getting us access to that server. And so in that case, we also have a separate terminal view in this case, within the SAGEMAKER notebook instance, your terminal is really valuable because it lets you see what your instances actually operating out on a line by line basis. So rather than the notebook view limiting you, you condone drop all the way down to the basho. Your EBS volume is going to start at that stage maker word, right, So you actually need to CD into sage maker to get onto your EBS volumes. And again, that's where your data is actually gonna be persisting. Okay, so, uh, again 200 example notebooks definitely use these. So on the left hand side, we're gonna see all of those folders those folders are working out over different cases of applying machine learning, different types of machine learning algorithms. Using are different types of data distribution. Every time you selection of those, just go ahead and hit use and then create a copy. And that's actually gonna copy the files that you need to have into the home directory of your Jupiter notebook. And then all of those example No books are open sourced its on the right hand side, those air a get how that to get hub site That's full of those 200 plus examples. Okay, so when you open up a single notebook, this is what it's gonna look like. First off, we have cells. This is a cell. Each cell is gonna be broken down into either markdown or code, and you can see that right up there with that dropped on bar. A couple of their options those the two main ones markdown is gonna make your code look really, really nice. So you can get nice headers and night list views. But when you need actual code, just switch that down in the top right hand side of your notebook. You're going to see the actual colonel that you're running on and your kernel is a way of executing code, right? So it's either python and three or two or are if you've installed it or in a condo or any of the other capabilities that you're gonna need and all those, they're gonna come with your sagemaker notebook instance. And if you need to switch out your colonel, go ahead and do that. You've got the cell tab over there at the top, and you can also change it. So if for whatever reason, one of your variables gets destroyed because you're doing some awesome feature engineering technique that was a little bit tough. Go ahead and switch out your kernel and you'll be good in no time the next piece we want to know about so we're gonna need to import the sagemaker Python STK. So again, that's an open source library that the stage maker team is developing in order for us to use the methods that they've built. Ah, that's gonna include getting the execution role that's going to use an STS service that's actually grabbing the I am policy that's associated with our notebook and then is giving sage maker access to our s three bucket. We're gonna have our stage maker session. We're gonna have our default bucket. And so the default buckets that is gonna live inside of every account it's gonna be created when you run that line. If you want to use your own bucket, go ahead and just paste in the name of the bucket name. It definitely surprised me the first time I started using Boto three, but I definitely grew to like it because so many of your services you can just get to using methods are dirty built in. So you just need the name of your s three bucket. Let's check out an example. This is our AWS console. This is where we're gonna look at all of our services on the top of right hand side. We're gonna have the region that we're operating in. That is a physical location in the world where services are going to be a belts maintained and stored. And so let's make sure we're in North Virginia. That's my default. Then we'll cruise down and will select Amazon stage maker. Go ahead and type it in the search bar if you need to find it, and then that's going to take us to our dashboard. The dashboard is going to tell you about ground truth labeling jobs. You performed notebook instances, training jobs and inference capabilities that you'll need. Let's elect notebook instances. Let's cruise up to the top of right hand side where it says create a notebook instance. Go ahead and type in a name for a notebook instance and then, under instance time you'll see that there is a wide variety of easy to instance that we that we can pick from. And this is where you can get really flexible with your instance where you can absolutely start with something small. Start with your your teeth three. Medium, but then you can bump up. You can absolutely upgrade on bits fun, because you can do this on the fly. So after you've started running her notebook instance, and then suddenly you realize that you need more memory or more processing. Go ahead and bump up your easy to instance. We'll leave this at the at the T two medium. You got your elastic inference. You can just attach that as necessary additional conflicts. So this is your Bash script right? That's that lifecycle conflict that's gonna run every time you create or start a notebook instance. And then here's your EBS volume. You can just specify any type of ups volume size you're looking for. The max is 16 terabytes. Here's your execution role, so that's going to give you access to the services. Ah, here's where you can enable or disable root access. You could encrypt your notebooks. You can operate them securely using the VPC and you can attach to get repository. I already have a noble created. Well, check this out. This is that home view on the top of right hand side. And that's where we can create a terminal. I'm gonna cruise up to Sage Maker. Example. So this time right here, That 4th 1 again. Wealth of information. Uh, in the first bar introduction. Amazon algorithms. Let's cruise down and select text classification TVP dia. Go ahead and hit, use and then create a copy, and that's gonna take us over here. Then we've got a couple different options for running through this lab. Every cell, which you'll see we can switch out from markdown to code. Believe as is if you want to run a single cell. The keyboard shortcut is shift. Enter. Here we go. So that's that's a single cell. However, if you want to confirm that all of the cells in your notebook are operating properly, go up and undersell, select, run all. And then that's just gonna run through every cell in your notebook, and this is gonna let you understand how this example operates. And so you see that empty space. So that means the cell hasn't been run, the wallets running. There's a little ass trick that shows you that it's processing. And when it's finished, you got a digit. That's the order in which that cell has run. And so you'll see in this first cell. This is we're importing stage maker. That's the python. Asi que. We're getting our execution role. We've got our session. We've got our default bucket, and this scenario, we're actually going to be copying a data set from the Internet s. Oh, this is from Sarraf. He's the author of the blazing text algorithm, and we're gonna be getting this data set from Hiss site and then we're gonna cruise down. And in this case, um, were getting a D v p a set s. Oh, this is coming from Wikipedia. There are 500,000 articles and all those 500,000 articles air tagged based on what category they fall into. So that's either author or company or means of transportation or a natural place. 14 different categories. Um And so here is the actual training data, as we call it. So each row is ah, sample from that data sent. We've got the class right up here, then the title of that article along with the abstract. And so these are the different 14 classes that we're looking at. Ah, here's a quick little mapper that's just going to create basically a hash map from the index face to the string. And then here we're gonna do some feature pre processing. And what I like about this example is that we're doing this pre processing in parallel on the notebook instance so even know, even though we only have two cores on that t three medium, we're going to be running our data through both of those cores using a map produce, and the colonel makes it super easy. Eso here is that single function right that takes a row, Runs through the transformation doing somewhere token izing blazing text. You do need this little label here, um, little string specifications. And then here's the actual map Produce s we're reading in all that data, depending it to this structure. Ah, calling Shuffle Keynote. Here. You do typically need to randomly shuffle all of your rose. Most algorithms. We're gonna assume that your data is gonna come in in a random fashion. Ah, you're only gonna keep a percentage of those rose. Ah, Then this is a count on the number of cores that are in that t three medium. Then we're gonna look at the actual function along with all of our data structures. And then the results from that is or transformed Rose. Right, So that comes out. Andi, here we go. And the rest will look at in the next section. I hope you like the demo eso some some pro tips here. So the 1st 1 is keeping your costs low by highly relying on land of write. Lambda is your friend. Ah, Lambda is event driven processing so you can keep it off of of the time of day. You can keep off oven. Upload s three. You can keep it off of a notification that's coming in, but definitely use Lambda to turn your notebook instances off when folks aren't using them in order to keep your costs down. Point number two resize on the fly So in this case, we were able to run all over processing with just that tea through medium. But let's say we wanted to use all that data, right? Not just a fraction we could actually increase that notebook instance. You just go ahead and select stop on your notebook instance and then edit your ec2 instance, or the EBS volumes. Both of those will recreate. Ah, the multi threading we talked about definitely nice feature and then that execution role. Keep in mind how you're actually attaching new policies to that execution rule. And so that's it. Thank you very much. My name is Emily Weber. I'm a machine learning specialist at Amazon Web services. I hope you enjoyed learning about notebook instances. Go ahead and check out our get hub site. Amazon Sagemaker examples\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_transcript_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences_and_times_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 -- Hi.\n",
      "1.36 -- My name is Emily Weber.\n",
      "2.74 -- I'm a machine learning specialist at Amazon Web services on today.\n",
      "5.99 -- We're gonna talk about insolence.\n",
      "7.03 -- Age maker Comes on Stage Maker is a fully managed machine learning service that developers and data scientists can use to build, train and deploy machine learning models.\n",
      "17.89 -- Today, we're gonna talk about notebook instances and this is ready.\n",
      "21.2 -- Dive.\n",
      "23.94 -- So with the notebook instances on stage maker, it all starts with a notebook, right?\n",
      "28.69 -- And within the notebook, it starts with your easy to instance.\n",
      "31.82 -- You're easy to instance that's your elastic compute cloud.\n",
      "34.36 -- That's your virtual machine that's going to spin up and let us do all of our processing.\n",
      "38.48 -- This is a managed, easy to instance.\n",
      "41.09 -- That means that even though we're turning it on and off, it's not gonna show up.\n",
      "44.84 -- Under are easy to console, and we're not gonna have ssh access to this machine.\n",
      "49.76 -- It's gonna be fully managed by Amazon.\n",
      "52.46 -- We want to pick the right family.\n",
      "54.38 -- You're easy to instances gonna come in many different shapes and sizes.\n",
      "57.67 -- And there are families of easy to instance.\n",
      "60.35 -- T is the tiny that's the smallest, most frugal, most humble option, and the is slightly larger.\n",
      "67.81 -- That's gonna have more memory.\n",
      "69.11 -- And more cores, see is compute optimized and P stands for GPU.\n",
      "75.14 -- After that, you're gonna want to pick the right size, and this is gonna range anywhere from medium to very, very large.\n",
      "81.53 -- You can have a lot of flexibility with selecting the right size on your easy to instance.\n",
      "86.84 -- Also, you want to pick the right version.\n",
      "89.12 -- So every version of Annecy two instance is of the latest version that's been produced by the team.\n",
      "95.6 -- So that three that's highlighted that stands for the most recent version in the T family.\n",
      "101.42 -- The large number of means that it came out more recently and the latest version of an easy two instances always gonna be more cost optimal.\n",
      "109.34 -- After that, we're gonna want to add an E.\n",
      "111.76 -- B s volume.\n",
      "113.21 -- And so again, Sage maker is a managed service.\n",
      "116.23 -- So the CBS volume is also not going to show up under EBS views.\n",
      "120.87 -- However, sage maker is gonna be putting these two things together for us.\n",
      "124.92 -- Any BS has a really special property.\n",
      "127.37 -- That property is that it's gonna be able to store data for us.\n",
      "131.35 -- So we want to get the size right.\n",
      "133.13 -- By default, you're gonna get five gigabytes.\n",
      "135.55 -- However, if you're working on a machine learning project that has more than five gigs which many, many machine learning products do have more than five gigs, we're gonna want to pick the right EBS volume for you.\n",
      "147.36 -- And typically, I do slightly more than the amount of data that I actually need.\n",
      "151.54 -- I'm not trying to have a large volume and then be charged for it.\n",
      "154.73 -- But you want a little bit of breathing room, So So pick something that's slightly larger than what do you actually need?\n",
      "159.95 -- And then on top of that, remember that everything on that EBS volume is gonna persist.\n",
      "165.39 -- So, you know, even if we turn our easy to instance on and off for simple when we go home at the end of the day, in order to keep our costs down, we still want to hold on to that data set, and we want to hold onto our code.\n",
      "177.22 -- And both of those are gonna live on TBS.\n",
      "180.04 -- We also want to add or create a git repository.\n",
      "184.03 -- And so those repositories are gonna give us access to Oliver code.\n",
      "188.37 -- It's how we're gonna share our code with other developers and data scientists.\n",
      "191.89 -- And with in sagemaker, you can add get repositories that are automatically installed onto notebook instance, one that's created after that.\n",
      "199.83 -- A few more settings.\n",
      "200.94 -- So we have security settings.\n",
      "202.53 -- This is gonna include topics like encryption.\n",
      "205.07 -- If we're working with extremely sensitive data, we want to make sure that it's encrypted properly, including root volume access to our instant.\n",
      "212.23 -- So if we need to shut that down under secure settings, we certainly can.\n",
      "215.97 -- Internet access is another component.\n",
      "218.1 -- If we want to disable Internet access, we've full capacity to do that.\n",
      "222.33 -- In addition to connecting our notebook instance to our vpc so that it's locked down within that virtual firewall.\n",
      "229.34 -- Also, we have the option of using a lifecycle configuration.\n",
      "233.56 -- Your life cycle conflict is a bash script that's gonna run every time you start or create a notebook instance, and it's just a bash shell so you can get cloned.\n",
      "242.7 -- You can pip install.\n",
      "243.67 -- You can copy data from S three that is gonna have a time out of run around 15 minutes.\n",
      "248.96 -- And so if you are installing a package that takes longer of them that time out.\n",
      "254.4 -- Go ahead and drop in an ampersand in the lines so that it actually runs in background of your notebook.\n",
      "258.91 -- Instance.\n",
      "260.14 -- After that, if you want to run a machinery model on that no book instance, we're going to cover all of the five ways that you can train models in stage Maker locally is just one of them, but you certainly can.\n",
      "272.88 -- You can attach a portion of a GPU to that easy to instance, and that is a new instance size that came out a new instance.\n",
      "280.44 -- Siri's that's called elastic inference.\n",
      "282.54 -- And this elastic inference is a portion of a GPU that you can attach directly to your easy to instance in order to run inference locally, and you're gonna want us to let that based on your size version and bandwidth after that.\n",
      "293.82 -- So you got your notebook instance created, and then you'll click the button that says, Open Jupiter, and that's going to take you to this page.\n",
      "300.94 -- If you're new to Jupiter, we're gonna walk you through some of the features here.\n",
      "304.32 -- So first off, that is all of your data.\n",
      "307.04 -- All the folders, all the files, all the content that you want actually process is sitting right there in that list.\n",
      "312.62 -- For men that forth have been from the right those Air 200 example notebooks that are managed by the stage maker team section.\n",
      "321.45 -- Those are actually coming out directly from us in order to show our customers features that they need to know about.\n",
      "327.7 -- So if they're interested in understanding how stage Maker's gonna handle training machine learning models using our or using care, OSCE or PYTORCH or any other capabilities in addition to distributing data sets wanted by putt mode, all of those examples are in that folder.\n",
      "343.75 -- Also over on the right hand side, there's a new button.\n",
      "346.52 -- You can select the new button and then cruise down to create new notebooks and terminals.\n",
      "351.92 -- We're gonna learn about the terminal feature right here.\n",
      "355.54 -- So on the right hand side, you select new and then down on the left hand side, you're gonna select create a new terminal, and then this is gonna open up your view.\n",
      "365.27 -- And so the terminal that is something that exists within every Jupiter environment that folks are gonna use.\n",
      "372.92 -- However, many of us weren't necessarily aware of it prior to using sage maker because the most common polices to develop Jupiter's based solutions are either on a desktop or there on a server.\n",
      "385.4 -- And if they're on a desktop, we typically already have a bash shell that's already opened up.\n",
      "388.93 -- So we wouldn't even need to see it within that desktop view.\n",
      "392.39 -- And if it's on a server than typically will have a putty or some type of other ssh connection that's actually getting us access to that server.\n",
      "399.4 -- And so in that case, we also have a separate terminal view in this case, within the SAGEMAKER notebook instance, your terminal is really valuable because it lets you see what your instances actually operating out on a line by line basis.\n",
      "411.43 -- So rather than the notebook view limiting you, you condone drop all the way down to the basho.\n",
      "416.47 -- Your EBS volume is going to start at that stage maker word, right, So you actually need to CD into sage maker to get onto your EBS volumes.\n",
      "424.94 -- And again, that's where your data is actually gonna be persisting.\n",
      "428.04 -- Okay, so, uh, again 200 example notebooks definitely use these.\n",
      "433.04 -- So on the left hand side, we're gonna see all of those folders those folders are working out over different cases of applying machine learning, different types of machine learning algorithms.\n",
      "444.22 -- Using are different types of data distribution.\n",
      "447.31 -- Every time you selection of those, just go ahead and hit use and then create a copy.\n",
      "451.44 -- And that's actually gonna copy the files that you need to have into the home directory of your Jupiter notebook.\n",
      "457.18 -- And then all of those example No books are open sourced its on the right hand side, those air a get how that to get hub site That's full of those 200 plus examples.\n",
      "466.56 -- Okay, so when you open up a single notebook, this is what it's gonna look like.\n",
      "470.59 -- First off, we have cells.\n",
      "472.74 -- This is a cell.\n",
      "474.39 -- Each cell is gonna be broken down into either markdown or code, and you can see that right up there with that dropped on bar.\n",
      "480.75 -- A couple of their options those the two main ones markdown is gonna make your code look really, really nice.\n",
      "485.48 -- So you can get nice headers and night list views.\n",
      "487.87 -- But when you need actual code, just switch that down in the top right hand side of your notebook.\n",
      "494.06 -- You're going to see the actual colonel that you're running on and your kernel is a way of executing code, right?\n",
      "499.58 -- So it's either python and three or two or are if you've installed it or in a condo or any of the other capabilities that you're gonna need and all those, they're gonna come with your sagemaker notebook instance.\n",
      "511.64 -- And if you need to switch out your colonel, go ahead and do that.\n",
      "514.11 -- You've got the cell tab over there at the top, and you can also change it.\n",
      "517.63 -- So if for whatever reason, one of your variables gets destroyed because you're doing some awesome feature engineering technique that was a little bit tough.\n",
      "524.9 -- Go ahead and switch out your kernel and you'll be good in no time the next piece we want to know about so we're gonna need to import the sagemaker Python STK.\n",
      "533.88 -- So again, that's an open source library that the stage maker team is developing in order for us to use the methods that they've built.\n",
      "541.99 -- Ah, that's gonna include getting the execution role that's going to use an STS service that's actually grabbing the I am policy that's associated with our notebook and then is giving sage maker access to our s three bucket.\n",
      "553.94 -- We're gonna have our stage maker session.\n",
      "555.87 -- We're gonna have our default bucket.\n",
      "557.35 -- And so the default buckets that is gonna live inside of every account it's gonna be created when you run that line.\n",
      "564.52 -- If you want to use your own bucket, go ahead and just paste in the name of the bucket name.\n",
      "569.85 -- It definitely surprised me the first time I started using Boto three, but I definitely grew to like it because so many of your services you can just get to using methods are dirty built in.\n",
      "579.92 -- So you just need the name of your s three bucket.\n",
      "583.44 -- Let's check out an example.\n",
      "585.14 -- This is our AWS console.\n",
      "587.61 -- This is where we're gonna look at all of our services on the top of right hand side.\n",
      "590.92 -- We're gonna have the region that we're operating in.\n",
      "593.26 -- That is a physical location in the world where services are going to be a belts maintained and stored.\n",
      "598.01 -- And so let's make sure we're in North Virginia.\n",
      "600.62 -- That's my default.\n",
      "602.04 -- Then we'll cruise down and will select Amazon stage maker.\n",
      "605.18 -- Go ahead and type it in the search bar if you need to find it, and then that's going to take us to our dashboard.\n",
      "611.86 -- The dashboard is going to tell you about ground truth labeling jobs.\n",
      "614.7 -- You performed notebook instances, training jobs and inference capabilities that you'll need.\n",
      "620.84 -- Let's elect notebook instances.\n",
      "623.81 -- Let's cruise up to the top of right hand side where it says create a notebook instance.\n",
      "629.74 -- Go ahead and type in a name for a notebook instance and then, under instance time you'll see that there is a wide variety of easy to instance that we that we can pick from.\n",
      "642.49 -- And this is where you can get really flexible with your instance where you can absolutely start with something small.\n",
      "648.97 -- Start with your your teeth three.\n",
      "650.54 -- Medium, but then you can bump up.\n",
      "652.6 -- You can absolutely upgrade on bits fun, because you can do this on the fly.\n",
      "657.38 -- So after you've started running her notebook instance, and then suddenly you realize that you need more memory or more processing.\n",
      "663.41 -- Go ahead and bump up your easy to instance.\n",
      "665.5 -- We'll leave this at the at the T two medium.\n",
      "668.34 -- You got your elastic inference.\n",
      "670.02 -- You can just attach that as necessary additional conflicts.\n",
      "673.95 -- So this is your Bash script right?\n",
      "676.81 -- That's that lifecycle conflict that's gonna run every time you create or start a notebook instance.\n",
      "683.14 -- And then here's your EBS volume.\n",
      "684.83 -- You can just specify any type of ups volume size you're looking for.\n",
      "689.45 -- The max is 16 terabytes.\n",
      "691.84 -- Here's your execution role, so that's going to give you access to the services.\n",
      "695.94 -- Ah, here's where you can enable or disable root access.\n",
      "699.44 -- You could encrypt your notebooks.\n",
      "700.97 -- You can operate them securely using the VPC and you can attach to get repository.\n",
      "706.6 -- I already have a noble created.\n",
      "709.04 -- Well, check this out.\n",
      "711.54 -- This is that home view on the top of right hand side.\n",
      "714.49 -- And that's where we can create a terminal.\n",
      "717.28 -- I'm gonna cruise up to Sage Maker.\n",
      "719.11 -- Example.\n",
      "719.83 -- So this time right here, That 4th 1 again.\n",
      "722.81 -- Wealth of information.\n",
      "724.24 -- Uh, in the first bar introduction.\n",
      "726.94 -- Amazon algorithms.\n",
      "728.47 -- Let's cruise down and select text classification TVP dia.\n",
      "732.94 -- Go ahead and hit, use and then create a copy, and that's gonna take us over here.\n",
      "739.54 -- Then we've got a couple different options for running through this lab.\n",
      "744.14 -- Every cell, which you'll see we can switch out from markdown to code.\n",
      "749.28 -- Believe as is if you want to run a single cell.\n",
      "751.92 -- The keyboard shortcut is shift.\n",
      "753.6 -- Enter.\n",
      "756.14 -- Here we go.\n",
      "757.24 -- So that's that's a single cell.\n",
      "758.82 -- However, if you want to confirm that all of the cells in your notebook are operating properly, go up and undersell, select, run all.\n",
      "769.54 -- And then that's just gonna run through every cell in your notebook, and this is gonna let you understand how this example operates.\n",
      "775.68 -- And so you see that empty space.\n",
      "777.81 -- So that means the cell hasn't been run, the wallets running.\n",
      "781.3 -- There's a little ass trick that shows you that it's processing.\n",
      "783.41 -- And when it's finished, you got a digit.\n",
      "785.32 -- That's the order in which that cell has run.\n",
      "787.74 -- And so you'll see in this first cell.\n",
      "789.38 -- This is we're importing stage maker.\n",
      "790.94 -- That's the python.\n",
      "791.63 -- Asi que.\n",
      "792.5 -- We're getting our execution role.\n",
      "794.2 -- We've got our session.\n",
      "795.57 -- We've got our default bucket, and this scenario, we're actually going to be copying a data set from the Internet s.\n",
      "802.09 -- Oh, this is from Sarraf.\n",
      "803.07 -- He's the author of the blazing text algorithm, and we're gonna be getting this data set from Hiss site and then we're gonna cruise down.\n",
      "812.85 -- And in this case, um, were getting a D v p a set s.\n",
      "818.59 -- Oh, this is coming from Wikipedia.\n",
      "819.83 -- There are 500,000 articles and all those 500,000 articles air tagged based on what category they fall into.\n",
      "827.3 -- So that's either author or company or means of transportation or a natural place.\n",
      "832.84 -- 14 different categories.\n",
      "834.43 -- Um And so here is the actual training data, as we call it.\n",
      "838.52 -- So each row is ah, sample from that data sent.\n",
      "842.01 -- We've got the class right up here, then the title of that article along with the abstract.\n",
      "847.74 -- And so these are the different 14 classes that we're looking at.\n",
      "851.14 -- Ah, here's a quick little mapper that's just going to create basically a hash map from the index face to the string.\n",
      "857.4 -- And then here we're gonna do some feature pre processing.\n",
      "860.51 -- And what I like about this example is that we're doing this pre processing in parallel on the notebook instance so even know, even though we only have two cores on that t three medium, we're going to be running our data through both of those cores using a map produce, and the colonel makes it super easy.\n",
      "876.52 -- Eso here is that single function right that takes a row, Runs through the transformation doing somewhere token izing blazing text.\n",
      "884.79 -- You do need this little label here, um, little string specifications.\n",
      "889.21 -- And then here's the actual map Produce s we're reading in all that data, depending it to this structure.\n",
      "894.85 -- Ah, calling Shuffle Keynote.\n",
      "897.3 -- Here.\n",
      "897.46 -- You do typically need to randomly shuffle all of your rose.\n",
      "901.32 -- Most algorithms.\n",
      "902.74 -- We're gonna assume that your data is gonna come in in a random fashion.\n",
      "905.94 -- Ah, you're only gonna keep a percentage of those rose.\n",
      "909.6 -- Ah, Then this is a count on the number of cores that are in that t three medium.\n",
      "914.25 -- Then we're gonna look at the actual function along with all of our data structures.\n",
      "918.31 -- And then the results from that is or transformed Rose.\n",
      "921.16 -- Right, So that comes out.\n",
      "922.74 -- Andi, here we go.\n",
      "924.44 -- And the rest will look at in the next section.\n",
      "927.24 -- I hope you like the demo eso some some pro tips here.\n",
      "930.88 -- So the 1st 1 is keeping your costs low by highly relying on land of write.\n",
      "936.31 -- Lambda is your friend.\n",
      "937.89 -- Ah, Lambda is event driven processing so you can keep it off of of the time of day.\n",
      "943.84 -- You can keep off oven.\n",
      "944.94 -- Upload s three.\n",
      "945.92 -- You can keep it off of a notification that's coming in, but definitely use Lambda to turn your notebook instances off when folks aren't using them in order to keep your costs down.\n",
      "955.24 -- Point number two resize on the fly So in this case, we were able to run all over processing with just that tea through medium.\n",
      "962.66 -- But let's say we wanted to use all that data, right?\n",
      "965.18 -- Not just a fraction we could actually increase that notebook instance.\n",
      "969.01 -- You just go ahead and select stop on your notebook instance and then edit your ec2 instance, or the EBS volumes.\n",
      "975.34 -- Both of those will recreate.\n",
      "976.94 -- Ah, the multi threading we talked about definitely nice feature and then that execution role.\n",
      "981.24 -- Keep in mind how you're actually attaching new policies to that execution rule.\n",
      "984.76 -- And so that's it.\n",
      "986.14 -- Thank you very much.\n",
      "987.04 -- My name is Emily Weber.\n",
      "988.36 -- I'm a machine learning specialist at Amazon Web services.\n",
      "991.27 -- I hope you enjoyed learning about notebook instances.\n",
      "994.18 -- Go ahead and check out our get hub site.\n"
     ]
    }
   ],
   "source": [
    "for tup in sentences_and_times_1:\n",
    "    print(str(tup['time']) + \" -- \" + tup['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
